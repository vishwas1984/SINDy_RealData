{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from typing import Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.tuner import Tuner\n",
    "from lightning.pytorch.callbacks import EarlyStopping\n",
    "\n",
    "import pytorch_forecasting as ptf\n",
    "from pytorch_forecasting import TimeSeriesDataSet, DeepAR, NHiTS, TemporalFusionTransformer, RecurrentNetwork, DecoderMLP\n",
    "from pytorch_forecasting.data import NaNLabelEncoder, TorchNormalizer, EncoderNormalizer\n",
    "from pytorch_forecasting.metrics import RMSE, NormalDistributionLoss, MultivariateNormalDistributionLoss, MQF2DistributionLoss, QuantileLoss\n",
    "from pytorch_forecasting.models import BaseModel\n",
    "\n",
    "from gp_mjo.utils.create_df import create_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['year', 'month', 'day', 'RMM1', 'RMM2', 'phase', 'amplitude']\n",
      "(16624,)\n"
     ]
    }
   ],
   "source": [
    "npzfile = np.load('../data/obs/mjo_new_data.npz', allow_pickle=True)\n",
    "print(npzfile.files)\n",
    "print(npzfile['RMM1'].shape)\n",
    "\n",
    "data_names = npzfile.files + ['id']\n",
    "n_files = len(data_names)\n",
    "\n",
    "entire_npzfile = {}\n",
    "for i, data_name in enumerate(data_names):\n",
    "    if i < n_files-1:\n",
    "        entire_npzfile[data_name] = npzfile[data_name]\n",
    "    if i == n_files-1:\n",
    "        entire_npzfile[data_name] = np.arange(len(npzfile['RMM1']))\n",
    "\n",
    "# Create the DataFrame using the function\n",
    "df = create_dataframe(entire_npzfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          value group  time_idx        date  phase  amplitude\n",
      "0      0.142507  RMM1         0  1979-01-01    6.0   1.060090\n",
      "1     -0.204200  RMM1         1  1979-01-02    7.0   1.388700\n",
      "2     -0.158610  RMM1         2  1979-01-03    7.0   1.547580\n",
      "3     -0.182450  RMM1         3  1979-01-04    7.0   1.471080\n",
      "4     -0.320050  RMM1         4  1979-01-05    7.0   1.181000\n",
      "...         ...   ...       ...         ...    ...        ...\n",
      "16619  0.386045  RMM1     16619  2024-07-02    3.0   1.455303\n",
      "16620  0.367469  RMM1     16620  2024-07-03    3.0   1.589958\n",
      "16621  0.209546  RMM1     16621  2024-07-04    3.0   1.466880\n",
      "16622  0.202304  RMM1     16622  2024-07-05    3.0   1.178915\n",
      "16623  0.412928  RMM1     16623  2024-07-06    3.0   1.128464\n",
      "\n",
      "[16624 rows x 6 columns]\n",
      "          value group  time_idx        date  phase  amplitude\n",
      "16624  1.050470  RMM2         0  1979-01-01    6.0   1.060090\n",
      "16625  1.373610  RMM2         1  1979-01-02    7.0   1.388700\n",
      "16626  1.539430  RMM2         2  1979-01-03    7.0   1.547580\n",
      "16627  1.459720  RMM2         3  1979-01-04    7.0   1.471080\n",
      "16628  1.136800  RMM2         4  1979-01-05    7.0   1.181000\n",
      "...         ...   ...       ...         ...    ...        ...\n",
      "33243 -1.403167  RMM2     16619  2024-07-02    3.0   1.455303\n",
      "33244 -1.546910  RMM2     16620  2024-07-03    3.0   1.589958\n",
      "33245 -1.451836  RMM2     16621  2024-07-04    3.0   1.466880\n",
      "33246 -1.161427  RMM2     16622  2024-07-05    3.0   1.178915\n",
      "33247 -1.050201  RMM2     16623  2024-07-06    3.0   1.128464\n",
      "\n",
      "[16624 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df[0:16624])\n",
    "\n",
    "print(df[16624:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset and dataloaders\n",
    "width = 40\n",
    "lead_time = 60\n",
    "n_pred = 528\n",
    "n = 10000\n",
    "v = 2000\n",
    "m = 5000\n",
    "start_train = 0\n",
    "n_offset = 0\n",
    "\n",
    "batch_size = 128\n",
    "seed = 99\n",
    "static_categoricals = []#['group'] #[] for 'NHiTS' 'FCNModel', ['group'] #as we plan to forecast correlations, it is important to use series characteristics (e.g. a series identifier)\n",
    "target_normalizer = None # None, TorchNormalizer(), EncoderNormalizer()\n",
    "\n",
    "training_cutoff = start_train + n + lead_time + width - 2 #df[\"time_idx\"].max() - lead_time\n",
    "\n",
    "start_forecast_val = training_cutoff + 1 + width # start_train + n + lead_time + n_offset \n",
    "validation_cutoff = start_forecast_val + v + lead_time - 2\n",
    "\n",
    "start_forecast_test = start_train + width + n + n_offset + width \\\n",
    "                + v + n_offset + 10 + width\n",
    "test_forecast_ids = np.arange( start_forecast_test, min( start_forecast_test + m, len(df) // 2 ) )\n",
    "test_cutoff = start_forecast_test + n_pred + lead_time - 2\n",
    "\n",
    "\n",
    "# create the dataset from the pandas dataframe\n",
    "training = TimeSeriesDataSet(\n",
    "    df[lambda x: x.time_idx <= training_cutoff],\n",
    "    target=\"value\",\n",
    "    time_idx=\"time_idx\",\n",
    "    group_ids=[\"group\"],\n",
    "    categorical_encoders={\"group\": NaNLabelEncoder().fit(df.group)},\n",
    "    static_categoricals = static_categoricals,\n",
    "    min_encoder_length=width,\n",
    "    max_encoder_length=width,\n",
    "    min_prediction_length=lead_time,\n",
    "    max_prediction_length=lead_time,\n",
    "    time_varying_unknown_reals=[\"value\"],\n",
    "    target_normalizer=target_normalizer,\n",
    ")\n",
    "\n",
    "\n",
    "validation = TimeSeriesDataSet(\n",
    "    df[lambda x: x.time_idx <= validation_cutoff],\n",
    "    target=\"value\",\n",
    "    time_idx=\"time_idx\",\n",
    "    group_ids=[\"group\"],\n",
    "    categorical_encoders={\"group\": NaNLabelEncoder().fit(df.group)},\n",
    "    static_categoricals = static_categoricals,\n",
    "    min_encoder_length=width,\n",
    "    max_encoder_length=width,\n",
    "    min_prediction_length=lead_time,\n",
    "    max_prediction_length=lead_time,\n",
    "    min_prediction_idx = start_forecast_val,\n",
    "    time_varying_unknown_reals=[\"value\"],\n",
    "    target_normalizer=target_normalizer,\n",
    ")\n",
    "\n",
    "test = TimeSeriesDataSet(\n",
    "    df[lambda x: x.time_idx <= test_cutoff],\n",
    "    target=\"value\",\n",
    "    time_idx=\"time_idx\",\n",
    "    group_ids=[\"group\"],\n",
    "    categorical_encoders={\"group\": NaNLabelEncoder().fit(df.group)},\n",
    "    static_categoricals = static_categoricals,\n",
    "    min_encoder_length=width,\n",
    "    max_encoder_length=width,\n",
    "    min_prediction_length=lead_time,\n",
    "    max_prediction_length=lead_time,\n",
    "    min_prediction_idx = start_forecast_test,\n",
    "    time_varying_unknown_reals=[\"value\"],\n",
    "    target_normalizer=target_normalizer,\n",
    ")\n",
    "\n",
    "# synchronize samples in each batch over time - only necessary for DeepVAR, not for DeepAR\n",
    "train_dataloader = training.to_dataloader(\n",
    "    train=True, batch_size=batch_size, num_workers=0, batch_sampler=\"synchronized\",\n",
    "    shuffle=True, generator=torch.Generator().manual_seed(seed),\n",
    ")\n",
    "val_dataloader = validation.to_dataloader(\n",
    "    train=False, batch_size=batch_size, num_workers=0, batch_sampler=\"synchronized\",\n",
    "    shuffle=True, generator=torch.Generator().manual_seed(seed),\n",
    ")\n",
    "test_dataloader = test.to_dataloader(\n",
    "    train=False, batch_size=batch_size, num_workers=0, batch_sampler=\"synchronized\",\n",
    "    shuffle=True, generator=torch.Generator().manual_seed(seed),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeSeriesDataSet[length=20000](\n",
      "\ttime_idx='time_idx',\n",
      "\ttarget='value',\n",
      "\tgroup_ids=['group'],\n",
      "\tweight=None,\n",
      "\tmax_encoder_length=40,\n",
      "\tmin_encoder_length=40,\n",
      "\tmin_prediction_idx=0,\n",
      "\tmin_prediction_length=60,\n",
      "\tmax_prediction_length=60,\n",
      "\tstatic_categoricals=[],\n",
      "\tstatic_reals=[],\n",
      "\ttime_varying_known_categoricals=[],\n",
      "\ttime_varying_known_reals=[],\n",
      "\ttime_varying_unknown_categoricals=[],\n",
      "\ttime_varying_unknown_reals=['value'],\n",
      "\tvariable_groups={},\n",
      "\tconstant_fill_strategy={},\n",
      "\tallow_missing_timesteps=False,\n",
      "\tlags={},\n",
      "\tadd_relative_time_idx=False,\n",
      "\tadd_target_scales=False,\n",
      "\tadd_encoder_length=False,\n",
      "\ttarget_normalizer=TorchNormalizer(method='identity', center=True, transformation=None, method_kwargs={}),\n",
      "\tcategorical_encoders={'group': NaNLabelEncoder(add_nan=False, warn=True), '__group_id__group': NaNLabelEncoder(add_nan=False, warn=True)},\n",
      "\tscalers={},\n",
      "\trandomize_length=None,\n",
      "\tpredict_mode=False\n",
      ")\n",
      "TimeSeriesDataSet[length=4000](\n",
      "\ttime_idx='time_idx',\n",
      "\ttarget='value',\n",
      "\tgroup_ids=['group'],\n",
      "\tweight=None,\n",
      "\tmax_encoder_length=40,\n",
      "\tmin_encoder_length=40,\n",
      "\tmin_prediction_idx=10139,\n",
      "\tmin_prediction_length=60,\n",
      "\tmax_prediction_length=60,\n",
      "\tstatic_categoricals=[],\n",
      "\tstatic_reals=[],\n",
      "\ttime_varying_known_categoricals=[],\n",
      "\ttime_varying_known_reals=[],\n",
      "\ttime_varying_unknown_categoricals=[],\n",
      "\ttime_varying_unknown_reals=['value'],\n",
      "\tvariable_groups={},\n",
      "\tconstant_fill_strategy={},\n",
      "\tallow_missing_timesteps=False,\n",
      "\tlags={},\n",
      "\tadd_relative_time_idx=False,\n",
      "\tadd_target_scales=False,\n",
      "\tadd_encoder_length=False,\n",
      "\ttarget_normalizer=TorchNormalizer(method='identity', center=True, transformation=None, method_kwargs={}),\n",
      "\tcategorical_encoders={'group': NaNLabelEncoder(add_nan=False, warn=True), '__group_id__group': NaNLabelEncoder(add_nan=False, warn=True)},\n",
      "\tscalers={},\n",
      "\trandomize_length=None,\n",
      "\tpredict_mode=False\n",
      ")\n",
      "TimeSeriesDataSet[length=1056](\n",
      "\ttime_idx='time_idx',\n",
      "\ttarget='value',\n",
      "\tgroup_ids=['group'],\n",
      "\tweight=None,\n",
      "\tmax_encoder_length=40,\n",
      "\tmin_encoder_length=40,\n",
      "\tmin_prediction_idx=12130,\n",
      "\tmin_prediction_length=60,\n",
      "\tmax_prediction_length=60,\n",
      "\tstatic_categoricals=[],\n",
      "\tstatic_reals=[],\n",
      "\ttime_varying_known_categoricals=[],\n",
      "\ttime_varying_known_reals=[],\n",
      "\ttime_varying_unknown_categoricals=[],\n",
      "\ttime_varying_unknown_reals=['value'],\n",
      "\tvariable_groups={},\n",
      "\tconstant_fill_strategy={},\n",
      "\tallow_missing_timesteps=False,\n",
      "\tlags={},\n",
      "\tadd_relative_time_idx=False,\n",
      "\tadd_target_scales=False,\n",
      "\tadd_encoder_length=False,\n",
      "\ttarget_normalizer=TorchNormalizer(method='identity', center=True, transformation=None, method_kwargs={}),\n",
      "\tcategorical_encoders={'group': NaNLabelEncoder(add_nan=False, warn=True), '__group_id__group': NaNLabelEncoder(add_nan=False, warn=True)},\n",
      "\tscalers={},\n",
      "\trandomize_length=None,\n",
      "\tpredict_mode=False\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print( train_dataloader.dataset )\n",
    "print( val_dataloader.dataset )\n",
    "print( test_dataloader.dataset )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 99\n"
     ]
    }
   ],
   "source": [
    "device = \"cpu\" #[\"cpu\", \"mps\", \"cuda\", \"tpu\", \"hpu\"]\n",
    "pl.seed_everything(seed)\n",
    "\n",
    "hidden_size = 64\n",
    "lr = 3e-2\n",
    "rnn_layers = 1\n",
    "max_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(accelerator=\"cpu\", gradient_clip_val=1e-1)\n",
    "net = DeepAR.from_dataset(\n",
    "    training,\n",
    "    learning_rate=lr,\n",
    "    hidden_size=hidden_size,\n",
    "    rnn_layers=rnn_layers,\n",
    "    loss=MultivariateNormalDistributionLoss(rank=30),\n",
    "    optimizer=\"Adam\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding best initial lr:  99%|█████████▉| 99/100 [00:02<00:00, 46.13it/s]`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Finding best initial lr: 100%|██████████| 100/100 [00:02<00:00, 43.49it/s]\n",
      "Learning rate set to 0.056234132519034905\n",
      "Restoring states from the checkpoint path at /Users/hchen/gp-mjo/SINDy_RealData/experiments/.lr_find_c1b8bf1d-3cb1-4046-b314-ad8e97d2f943.ckpt\n",
      "Restored all states from the checkpoint at /Users/hchen/gp-mjo/SINDy_RealData/experiments/.lr_find_c1b8bf1d-3cb1-4046-b314-ad8e97d2f943.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suggested learning rate: 0.056234132519034905\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# find optimal learning rate\n",
    "res = Tuner(trainer).lr_find(\n",
    "    net,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    "    min_lr=1e-5,\n",
    "    max_lr=1e0,\n",
    "    early_stop_threshold=100,\n",
    ")\n",
    "print(f\"suggested learning rate: {res.suggestion()}\")\n",
    "fig = res.plot(show=True, suggest=True)\n",
    "fig.show()\n",
    "net.hparams.learning_rate = res.suggestion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name                   | Type                               | Params | Mode \n",
      "--------------------------------------------------------------------------------------\n",
      "0 | loss                   | MultivariateNormalDistributionLoss | 0      | train\n",
      "1 | logging_metrics        | ModuleList                         | 0      | train\n",
      "2 | embeddings             | MultiEmbedding                     | 2      | train\n",
      "3 | rnn                    | LSTM                               | 17.4 K | train\n",
      "4 | distribution_projector | Linear                             | 2.1 K  | train\n",
      "--------------------------------------------------------------------------------------\n",
      "19.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "19.5 K    Total params\n",
      "0.078     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 50/50 [04:18<00:00,  0.19it/s, v_num=35, train_loss_step=-0.182, val_loss=-0.268, train_loss_epoch=-0.217]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 50/50 [04:19<00:00,  0.19it/s, v_num=35, train_loss_step=-0.182, val_loss=-0.268, train_loss_epoch=-0.217]\n"
     ]
    }
   ],
   "source": [
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=10, verbose=False, mode=\"min\")\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=max_epochs,\n",
    "    accelerator=device,\n",
    "    enable_model_summary=True,\n",
    "    gradient_clip_val=0.1,\n",
    "    callbacks=[early_stop_callback],\n",
    "    limit_train_batches=50,\n",
    "    enable_checkpointing=True,\n",
    ")\n",
    "\n",
    "\n",
    "net = DeepAR.from_dataset(\n",
    "    training,\n",
    "    learning_rate=res.suggestion(),\n",
    "    log_interval=10,\n",
    "    log_val_interval=1,\n",
    "    hidden_size=hidden_size,\n",
    "    rnn_layers=rnn_layers,\n",
    "    optimizer=\"Adam\",\n",
    "    loss=MultivariateNormalDistributionLoss(rank=30),\n",
    ")\n",
    "\n",
    "trainer.fit(\n",
    "    net,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "best_model = DeepAR.load_from_checkpoint(best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# best_model = net\n",
    "predictions = best_model.predict(test_dataloader, mode=\"prediction\", \n",
    "                                trainer_kwargs=dict(accelerator=device), \n",
    "                                return_index=True, return_x=True, return_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "raw_predictions = net.predict(\n",
    "    test_dataloader, mode=\"raw\", \n",
    "    return_index=True, return_x=True, return_y=True, \n",
    "    n_samples=100, \n",
    "    trainer_kwargs=dict(accelerator=device)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1056, 60])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.x['decoder_target'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        True\n",
       "1       False\n",
       "2        True\n",
       "3       False\n",
       "4        True\n",
       "        ...  \n",
       "1051    False\n",
       "1052     True\n",
       "1053    False\n",
       "1054     True\n",
       "1055    False\n",
       "Name: group, Length: 1056, dtype: bool"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.index.group == 'RMM1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1056, 60, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_predictions.x['decoder_cont'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1056, 60])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_predictions.output[0].mean(dim=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.4858876 ,  1.4127605 ,  0.87013769,  0.36032364, -0.2242689 ,\n",
       "       -0.52937448, -0.56909633, -0.33208254])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entire_npzfile['RMM1'][start_forecast_test:start_forecast_test+8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.4859,  1.4128,  0.8701,  0.3603, -0.2243, -0.5294, -0.5691, -0.3321],\n",
      "        [ 2.1455,  2.9191,  3.2661,  3.2807,  3.2044,  3.2006,  2.7466,  2.1816],\n",
      "        [ 1.4128,  0.8701,  0.3603, -0.2243, -0.5294, -0.5691, -0.3321, -0.0778],\n",
      "        [ 2.9191,  3.2661,  3.2807,  3.2044,  3.2006,  2.7466,  2.1816,  1.7408]])\n",
      "tensor([[ 1.2471,  1.0196,  0.8272,  0.6206,  0.4258,  0.2958,  0.1818,  0.0432],\n",
      "        [ 1.6097,  1.2548,  0.8414,  0.4869,  0.2285, -0.0423, -0.2731, -0.4182],\n",
      "        [ 1.3870,  1.1560,  0.9537,  0.7165,  0.4707,  0.4230,  0.4124,  0.3936],\n",
      "        [ 2.1169,  1.6341,  1.1657,  0.7380,  0.3770,  0.0779, -0.2109, -0.3979]])\n"
     ]
    }
   ],
   "source": [
    "print(raw_predictions.x['decoder_target'][:4, :8])\n",
    "print(raw_predictions.output[0].mean(dim=-1)[:4, :8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7566)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lead_time_id = 0\n",
    "RMSE()(raw_predictions.x['decoder_cont'].squeeze()[:,lead_time_id][None,:], \n",
    "       raw_predictions.output[0].mean(dim=-1)[:,lead_time_id][None,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7560)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lead_time_id = 0\n",
    "RMSE()(predictions.x['decoder_cont'].squeeze()[:,lead_time_id][:,None], \n",
    "       predictions.output[:,lead_time_id][:,None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1056, 60])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.4239,  1.3409,  1.2561,  ..., -1.7521, -1.6877, -1.6196],\n",
       "        [ 1.4632,  1.4088,  1.3061,  ..., -1.8059, -1.7711, -1.7460],\n",
       "        [ 1.3893,  1.3717,  1.2565,  ..., -2.0053, -1.9316, -1.9248],\n",
       "        ...,\n",
       "        [-1.5626, -1.8241, -2.0137,  ..., -1.9796, -1.9755, -1.9901],\n",
       "        [-1.3055, -1.4449, -1.5756,  ..., -1.8870, -1.8625, -1.8465],\n",
       "        [-1.4148, -1.5460, -1.6694,  ..., -1.8822, -1.8896, -1.8480]])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.output[predictions.index.group == 'RMM1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([528, 60, 100])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_predictions.output[0][raw_predictions.index.group == 'RMM1'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.4239, 1.3409, 1.2561, 1.1243, 0.9648, 0.8177, 0.6118, 0.3598],\n",
       "        [1.4632, 1.4088, 1.3061, 1.1830, 1.0075, 0.8025, 0.6483, 0.4598],\n",
       "        [1.3893, 1.3717, 1.2565, 1.1139, 0.9733, 0.8386, 0.6476, 0.4889]])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.output[(0,2,4),:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.4859,  1.4128,  0.8701,  0.3603, -0.2243, -0.5294, -0.5691, -0.3321],\n",
       "        [ 1.4128,  0.8701,  0.3603, -0.2243, -0.5294, -0.5691, -0.3321, -0.0778],\n",
       "        [ 0.8701,  0.3603, -0.2243, -0.5294, -0.5691, -0.3321, -0.0778,  0.1272]])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.x['decoder_target'][predictions.index.group == 'RMM1'][:3,:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.4858876 ,  1.4127605 ,  0.87013769,  0.36032364, -0.2242689 ,\n",
       "       -0.52937448, -0.56909633, -0.33208254, -0.07775909,  0.12718512,\n",
       "        0.12812702])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entire_npzfile['RMM1'][start_forecast_test:start_forecast_test+11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NHiTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 99\n"
     ]
    }
   ],
   "source": [
    "device = \"cpu\" #[\"cpu\", \"mps\", \"cuda\", \"tpu\", \"hpu\"]\n",
    "pl.seed_everything(seed)\n",
    "\n",
    "hidden_size = 64\n",
    "lr = 3e-2\n",
    "rnn_layers = 1\n",
    "max_epochs = 5\n",
    "\n",
    "weight_decay = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 99\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "pl.seed_everything(seed)\n",
    "trainer = pl.Trainer(accelerator=device, gradient_clip_val=0.1)\n",
    "net = NHiTS.from_dataset(\n",
    "    training,\n",
    "    learning_rate=lr,\n",
    "    weight_decay=weight_decay,\n",
    "    loss=MQF2DistributionLoss(prediction_length=lead_time),\n",
    "    backcast_loss_ratio=0.0,\n",
    "    hidden_size=hidden_size,\n",
    "    optimizer=\"AdamW\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "free variable 'encoder_features' referenced before assignment in enclosing scope",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# find optimal learning rate\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mTuner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr_find\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_lr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_lr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-1\u001b[39;49m\n\u001b[1;32m      4\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msuggested learning rate: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mres\u001b[38;5;241m.\u001b[39msuggestion()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m fig \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39mplot(show\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, suggest\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/gp-mjo/SINDy_RealData/env_gp_mjo/lib/python3.9/site-packages/lightning/pytorch/tuner/tuning.py:180\u001b[0m, in \u001b[0;36mTuner.lr_find\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, dataloaders, datamodule, method, min_lr, max_lr, num_training, mode, early_stop_threshold, update_attr, attr_name)\u001b[0m\n\u001b[1;32m    177\u001b[0m lr_finder_callback\u001b[38;5;241m.\u001b[39m_early_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer\u001b[38;5;241m.\u001b[39mcallbacks \u001b[38;5;241m=\u001b[39m [lr_finder_callback] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer\u001b[38;5;241m.\u001b[39mcallbacks\n\u001b[0;32m--> 180\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer\u001b[38;5;241m.\u001b[39mcallbacks \u001b[38;5;241m=\u001b[39m [cb \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer\u001b[38;5;241m.\u001b[39mcallbacks \u001b[38;5;28;01mif\u001b[39;00m cb \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lr_finder_callback]\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m lr_finder_callback\u001b[38;5;241m.\u001b[39moptimal_lr\n",
      "File \u001b[0;32m~/gp-mjo/SINDy_RealData/env_gp_mjo/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py:543\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 543\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/gp-mjo/SINDy_RealData/env_gp_mjo/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/gp-mjo/SINDy_RealData/env_gp_mjo/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py:579\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    573\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    574\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    575\u001b[0m     ckpt_path,\n\u001b[1;32m    576\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    577\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    578\u001b[0m )\n\u001b[0;32m--> 579\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    581\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/gp-mjo/SINDy_RealData/env_gp_mjo/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py:966\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[38;5;66;03m# hook\u001b[39;00m\n\u001b[1;32m    965\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;241m==\u001b[39m TrainerFn\u001b[38;5;241m.\u001b[39mFITTING:\n\u001b[0;32m--> 966\u001b[0m     \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_callback_hooks\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mon_fit_start\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    967\u001b[0m     call\u001b[38;5;241m.\u001b[39m_call_lightning_module_hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_fit_start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    969\u001b[0m _log_hyperparams(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/gp-mjo/SINDy_RealData/env_gp_mjo/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py:210\u001b[0m, in \u001b[0;36m_call_callback_hooks\u001b[0;34m(trainer, hook_name, monitoring_callbacks, *args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(fn):\n\u001b[1;32m    209\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Callback]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcallback\u001b[38;5;241m.\u001b[39mstate_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 210\u001b[0m             \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pl_module:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/gp-mjo/SINDy_RealData/env_gp_mjo/lib/python3.9/site-packages/lightning/pytorch/callbacks/lr_finder.py:130\u001b[0m, in \u001b[0;36mLearningRateFinder.on_fit_start\u001b[0;34m(self, trainer, pl_module)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_fit_start\u001b[39m(\u001b[38;5;28mself\u001b[39m, trainer: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpl.Trainer\u001b[39m\u001b[38;5;124m\"\u001b[39m, pl_module: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpl.LightningModule\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 130\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr_find\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpl_module\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/gp-mjo/SINDy_RealData/env_gp_mjo/lib/python3.9/site-packages/lightning/pytorch/callbacks/lr_finder.py:113\u001b[0m, in \u001b[0;36mLearningRateFinder.lr_find\u001b[0;34m(self, trainer, pl_module)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlr_find\u001b[39m(\u001b[38;5;28mself\u001b[39m, trainer: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpl.Trainer\u001b[39m\u001b[38;5;124m\"\u001b[39m, pl_module: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpl.LightningModule\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n\u001b[0;32m--> 113\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimal_lr \u001b[38;5;241m=\u001b[39m \u001b[43m_lr_find\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpl_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmin_lr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_min_lr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_lr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_max_lr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_training\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_training_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m            \u001b[49m\u001b[43mearly_stop_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_early_stop_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m            \u001b[49m\u001b[43mupdate_attr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_attr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m            \u001b[49m\u001b[43mattr_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_attr_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_early_exit:\n\u001b[1;32m    126\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m _TunerExitException()\n",
      "File \u001b[0;32m~/gp-mjo/SINDy_RealData/env_gp_mjo/lib/python3.9/site-packages/lightning/pytorch/tuner/lr_finder.py:275\u001b[0m, in \u001b[0;36m_lr_find\u001b[0;34m(trainer, model, min_lr, max_lr, num_training, mode, early_stop_threshold, update_attr, attr_name)\u001b[0m\n\u001b[1;32m    272\u001b[0m lr_finder\u001b[38;5;241m.\u001b[39m_exchange_scheduler(trainer)\n\u001b[1;32m    274\u001b[0m \u001b[38;5;66;03m# Fit, lr & loss logged in callback\u001b[39;00m\n\u001b[0;32m--> 275\u001b[0m \u001b[43m_try_loop_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;66;03m# Prompt if we stopped early\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m!=\u001b[39m num_training \u001b[38;5;241m+\u001b[39m start_steps:\n",
      "File \u001b[0;32m~/gp-mjo/SINDy_RealData/env_gp_mjo/lib/python3.9/site-packages/lightning/pytorch/tuner/lr_finder.py:520\u001b[0m, in \u001b[0;36m_try_loop_run\u001b[0;34m(trainer, params)\u001b[0m\n\u001b[1;32m    518\u001b[0m loop\u001b[38;5;241m.\u001b[39mload_state_dict(deepcopy(params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloop_state_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[1;32m    519\u001b[0m loop\u001b[38;5;241m.\u001b[39mrestarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 520\u001b[0m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/gp-mjo/SINDy_RealData/env_gp_mjo/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py:205\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start()\n\u001b[0;32m--> 205\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/gp-mjo/SINDy_RealData/env_gp_mjo/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py:363\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_training_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 363\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/gp-mjo/SINDy_RealData/env_gp_mjo/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py:141\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madvance(data_fetcher)\n\u001b[0;32m--> 141\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_advance_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "File \u001b[0;32m~/gp-mjo/SINDy_RealData/env_gp_mjo/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py:295\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.on_advance_end\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_accumulate():\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;66;03m# clear gradients to not leave any unused memory during validation\u001b[39;00m\n\u001b[1;32m    293\u001b[0m     call\u001b[38;5;241m.\u001b[39m_call_lightning_module_hook(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_validation_model_zero_grad\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 295\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39m_logger_connector\u001b[38;5;241m.\u001b[39m_first_loop_iter \u001b[38;5;241m=\u001b[39m first_loop_iter\n",
      "File \u001b[0;32m~/gp-mjo/SINDy_RealData/env_gp_mjo/lib/python3.9/site-packages/lightning/pytorch/loops/utilities.py:182\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m     context_manager \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mno_grad\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[0;32m--> 182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/gp-mjo/SINDy_RealData/env_gp_mjo/lib/python3.9/site-packages/lightning/pytorch/loops/evaluation_loop.py:135\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mis_last_batch \u001b[38;5;241m=\u001b[39m data_fetcher\u001b[38;5;241m.\u001b[39mdone\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;66;03m# run step hooks\u001b[39;00m\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;66;03m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[39;00m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/gp-mjo/SINDy_RealData/env_gp_mjo/lib/python3.9/site-packages/lightning/pytorch/loops/evaluation_loop.py:396\u001b[0m, in \u001b[0;36m_EvaluationLoop._evaluation_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx, dataloader_iter)\u001b[0m\n\u001b[1;32m    390\u001b[0m hook_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_step\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mtesting \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    391\u001b[0m step_args \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_step_args_from_hook_kwargs(hook_kwargs, hook_name)\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_dataloader_iter\n\u001b[1;32m    394\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m (dataloader_iter,)\n\u001b[1;32m    395\u001b[0m )\n\u001b[0;32m--> 396\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstep_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_processed()\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m using_dataloader_iter:\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;66;03m# update the hook kwargs now that the step method might have consumed the iterator\u001b[39;00m\n",
      "File \u001b[0;32m~/gp-mjo/SINDy_RealData/env_gp_mjo/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py:311\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 311\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    314\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/gp-mjo/SINDy_RealData/env_gp_mjo/lib/python3.9/site-packages/lightning/pytorch/strategies/strategy.py:411\u001b[0m, in \u001b[0;36mStrategy.validation_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module:\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_redirection(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 411\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/gp-mjo/SINDy_RealData/env_gp_mjo/lib/python3.9/site-packages/pytorch_forecasting/models/base_model.py:630\u001b[0m, in \u001b[0;36mBaseModel.validation_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidation_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, batch_idx):\n\u001b[1;32m    629\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m batch\n\u001b[0;32m--> 630\u001b[0m     log, out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m     log\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_log(x, y, out, batch_idx))\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidation_step_outputs\u001b[38;5;241m.\u001b[39mappend(log)\n",
      "File \u001b[0;32m~/gp-mjo/SINDy_RealData/env_gp_mjo/lib/python3.9/site-packages/pytorch_forecasting/models/nhits/__init__.py:354\u001b[0m, in \u001b[0;36mNHiTS.step\u001b[0;34m(self, x, y, batch_idx)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, y, batch_idx) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    351\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;124;03m    Take training / validation step.\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 354\u001b[0m     log, out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    356\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhparams\u001b[38;5;241m.\u001b[39mbackcast_loss_ratio \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredicting:  \u001b[38;5;66;03m# add loss from backcast\u001b[39;00m\n\u001b[1;32m    357\u001b[0m         backcast \u001b[38;5;241m=\u001b[39m out[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbackcast\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/gp-mjo/SINDy_RealData/env_gp_mjo/lib/python3.9/site-packages/pytorch_forecasting/models/base_model.py:777\u001b[0m, in \u001b[0;36mBaseModel.step\u001b[0;34m(self, x, y, batch_idx, **kwargs)\u001b[0m\n\u001b[1;32m    775\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 777\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;66;03m# calculate loss\u001b[39;00m\n\u001b[1;32m    780\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m out[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/gp-mjo/SINDy_RealData/env_gp_mjo/lib/python3.9/site-packages/torch/nn/modules/module.py:1657\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1657\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/gp-mjo/SINDy_RealData/env_gp_mjo/lib/python3.9/site-packages/torch/nn/modules/module.py:1668\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1664\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1665\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1666\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1667\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1668\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1670\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1671\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/gp-mjo/SINDy_RealData/env_gp_mjo/lib/python3.9/site-packages/pytorch_forecasting/models/nhits/__init__.py:256\u001b[0m, in \u001b[0;36mNHiTS.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;66;03m# statics\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatic_size \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 256\u001b[0m     x_s \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mconcat([encoder_features[name][:, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatic_variables], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     x_s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/gp-mjo/SINDy_RealData/env_gp_mjo/lib/python3.9/site-packages/pytorch_forecasting/models/nhits/__init__.py:256\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;66;03m# statics\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatic_size \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 256\u001b[0m     x_s \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mconcat([\u001b[43mencoder_features\u001b[49m[name][:, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatic_variables], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     x_s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: free variable 'encoder_features' referenced before assignment in enclosing scope"
     ]
    }
   ],
   "source": [
    "# find optimal learning rate\n",
    "res = Tuner(trainer).lr_find(\n",
    "    net, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader, min_lr=1e-5, max_lr=1e-1\n",
    ")\n",
    "print(f\"suggested learning rate: {res.suggestion()}\")\n",
    "fig = res.plot(show=True, suggest=True)\n",
    "fig.show()\n",
    "net.hparams.learning_rate = res.suggestion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_clip_val = 0.1\n",
    "limit_train_batches = 30 # 50 for DeepVAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type                 | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0 | loss            | MQF2DistributionLoss | 11.7 K | train\n",
      "1 | logging_metrics | ModuleList           | 0      | train\n",
      "2 | embeddings      | MultiEmbedding       | 0      | train\n",
      "3 | model           | NHiTS                | 39.9 K | train\n",
      "-----------------------------------------------------------------\n",
      "51.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "51.5 K    Total params\n",
      "0.206     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 30/30 [00:02<00:00, 10.18it/s, v_num=31, train_loss_step=0.123, val_loss=0.0943, train_loss_epoch=0.0896] "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=10, verbose=False, mode=\"min\")\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=max_epochs,\n",
    "    accelerator=device,\n",
    "    enable_model_summary=True,\n",
    "    gradient_clip_val=gradient_clip_val,\n",
    "    callbacks=[early_stop_callback],\n",
    "    limit_train_batches=limit_train_batches,\n",
    "    enable_checkpointing=True,\n",
    ")\n",
    "\n",
    "\n",
    "net = NHiTS.from_dataset(\n",
    "    training,\n",
    "    learning_rate=res.suggestion(),\n",
    "    log_interval=10,\n",
    "    log_val_interval=1,\n",
    "    weight_decay=weight_decay,\n",
    "    backcast_loss_ratio=0.0,\n",
    "    hidden_size=hidden_size,\n",
    "    optimizer=\"AdamW\",\n",
    "    loss=MQF2DistributionLoss(prediction_length=lead_time),\n",
    ")\n",
    "\n",
    "trainer.fit(\n",
    "    net,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "best_model = NHiTS.load_from_checkpoint(best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model = net\n",
    "predictions = best_model.predict(test_dataloader, mode=\"prediction\", \n",
    "                        trainer_kwargs=dict(accelerator=device), \n",
    "                        return_index=True, return_x=True, return_y=True)\n",
    "\n",
    "raw_predictions = net.predict(\n",
    "    test_dataloader, mode=\"raw\", \n",
    "    return_index=True, return_x=True, return_y=True, \n",
    "    n_samples=100, \n",
    "    trainer_kwargs=dict(accelerator=device)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_time_id = 0\n",
    "RMSE()(predictions.x['decoder_target'][:,lead_time_id][:,None], \n",
    "       predictions.output[:,lead_time_id][:,None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_time_id = 0\n",
    "RMSE()(raw_predictions.x['decoder_target'][:,lead_time_id][None,:], \n",
    "       raw_predictions.output[0].mean(dim=-1)[:,lead_time_id][None,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 99\n"
     ]
    }
   ],
   "source": [
    "device = \"cpu\" #[\"cpu\", \"mps\", \"cuda\", \"tpu\", \"hpu\"]\n",
    "pl.seed_everything(seed)\n",
    "\n",
    "hidden_size = 64\n",
    "lr = 3e-2\n",
    "rnn_layers = 1\n",
    "max_epochs = 5\n",
    "\n",
    "weight_decay = 1e-2\n",
    "cell_type = 'GRU' # ['LSTM', 'GRU']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCNModule(nn.Module):\n",
    "    def __init__(self, input_size: int, output_size: int, hidden_size: int, n_hidden_layers: int, n_outputs: int):\n",
    "        super().__init__()\n",
    "\n",
    "        # input layer\n",
    "        module_list = [nn.Linear(input_size, hidden_size), nn.ReLU()]\n",
    "        # hidden layers\n",
    "        for _ in range(n_hidden_layers):\n",
    "            module_list.extend([nn.Linear(hidden_size, hidden_size), nn.ReLU()])\n",
    "        # output layer\n",
    "        self.n_outputs = n_outputs\n",
    "        module_list.append(\n",
    "            nn.Linear(hidden_size, output_size * n_outputs)\n",
    "        )  # <<<<<<<< modified: replaced output_size with output_size * n_outputs\n",
    "\n",
    "        self.sequential = nn.Sequential(*module_list)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x of shape: batch_size x n_timesteps_in\n",
    "        # output of shape batch_size x n_timesteps_out\n",
    "        return self.sequential(x).reshape(x.size(0), -1, self.n_outputs)  # <<<<<<<< modified: added reshape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"hidden_size\":                 10\n",
       "\"input_size\":                  40\n",
       "\"learning_rate\":               0.001\n",
       "\"log_gradient_flow\":           False\n",
       "\"log_interval\":                -1\n",
       "\"log_val_interval\":            -1\n",
       "\"logging_metrics\":             ModuleList()\n",
       "\"monotone_constaints\":         {}\n",
       "\"n_hidden_layers\":             2\n",
       "\"optimizer\":                   Ranger\n",
       "\"optimizer_params\":            None\n",
       "\"output_size\":                 60\n",
       "\"output_transformer\":          TorchNormalizer(method='identity', center=True, transformation=None, method_kwargs={})\n",
       "\"reduce_on_plateau_min_lr\":    1e-05\n",
       "\"reduce_on_plateau_patience\":  1000\n",
       "\"reduce_on_plateau_reduction\": 2.0\n",
       "\"weight_decay\":                0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FCN(BaseModel):  # we inherit the `from_dataset` method\n",
    "    def __init__(self, input_size: int, output_size: int, hidden_size: int, n_hidden_layers: int, **kwargs):\n",
    "        # saves arguments in signature to `.hparams` attribute, mandatory call - do not skip this\n",
    "        self.save_hyperparameters()\n",
    "        # pass additional arguments to BaseModel.__init__, mandatory call - do not skip this\n",
    "        super().__init__(**kwargs)\n",
    "        self.network = FCNModule(\n",
    "            input_size=self.hparams.input_size,\n",
    "            output_size=self.hparams.output_size,\n",
    "            hidden_size=self.hparams.hidden_size,\n",
    "            n_hidden_layers=self.hparams.n_hidden_layers,\n",
    "            n_outputs=2,  # <<<<<<<< we predict two outputs for mean and scale of the normal distribution\n",
    "        )\n",
    "        self.loss = NormalDistributionLoss()\n",
    "\n",
    "    @classmethod\n",
    "    def from_dataset(cls, dataset: TimeSeriesDataSet, **kwargs):\n",
    "        new_kwargs = {\n",
    "            \"output_size\": dataset.max_prediction_length,\n",
    "            \"input_size\": dataset.max_encoder_length,\n",
    "        }\n",
    "        new_kwargs.update(kwargs)  # use to pass real hyperparameters and override defaults set by dataset\n",
    "        # example for dataset validation\n",
    "        assert dataset.max_prediction_length == dataset.min_prediction_length, \"Decoder only supports a fixed length\"\n",
    "        assert dataset.min_encoder_length == dataset.max_encoder_length, \"Encoder only supports a fixed length\"\n",
    "        assert (\n",
    "            len(dataset.time_varying_known_categoricals) == 0\n",
    "            and len(dataset.time_varying_known_reals) == 0\n",
    "            and len(dataset.time_varying_unknown_categoricals) == 0\n",
    "            and len(dataset.static_categoricals) == 0\n",
    "            and len(dataset.static_reals) == 0\n",
    "            and len(dataset.time_varying_unknown_reals) == 1\n",
    "            and dataset.time_varying_unknown_reals[0] == dataset.target\n",
    "        ), \"Only covariate should be the target in 'time_varying_unknown_reals'\"\n",
    "\n",
    "        return super().from_dataset(dataset, **new_kwargs)\n",
    "\n",
    "    def forward(self, x: Dict[str, torch.Tensor], n_samples: int = None) -> Dict[str, torch.Tensor]:\n",
    "        # x is a batch generated based on the TimeSeriesDataset\n",
    "        network_input = x[\"encoder_cont\"].squeeze(-1)\n",
    "        prediction = self.network(network_input)  # shape batch_size x n_decoder_steps x 2\n",
    "        # we need to scale the parameters to real space\n",
    "        prediction = self.transform_output(\n",
    "            prediction=prediction,\n",
    "            target_scale=x[\"target_scale\"],\n",
    "        )\n",
    "        if n_samples is not None:\n",
    "            # sample from distribution\n",
    "            prediction = self.loss.sample(prediction, n_samples)\n",
    "        # The conversion to a named tuple can be directly achieved with the `to_network_output` function.\n",
    "        return self.to_network_output(prediction=prediction)\n",
    "\n",
    "\n",
    "model = FCN.from_dataset(training, hidden_size=10, n_hidden_layers=2)\n",
    "model.hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 99\n"
     ]
    }
   ],
   "source": [
    "device = \"cpu\" #[\"cpu\", \"mps\", \"cuda\", \"tpu\", \"hpu\"]\n",
    "pl.seed_everything(seed)\n",
    "\n",
    "hidden_size = 64\n",
    "lr = 3e-2\n",
    "rnn_layers = 1\n",
    "max_epochs = 3\n",
    "n_hidden_layers=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(accelerator=device, gradient_clip_val=1e-1)\n",
    "net = FCN.from_dataset(\n",
    "    training,\n",
    "    learning_rate=lr,\n",
    "    hidden_size=hidden_size,\n",
    "    n_hidden_layers=n_hidden_layers,\n",
    "    loss=NormalDistributionLoss(),\n",
    "    optimizer=\"Adam\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding best initial lr:  92%|█████████▏| 92/100 [00:00<00:00, 443.53it/s]\n",
      "LR finder stopped early after 92 steps due to diverging loss.\n",
      "Learning rate set to 0.1445439770745927\n",
      "Restoring states from the checkpoint path at /Users/hchen/gp-mjo/SINDy_RealData/experiments/.lr_find_9f99eb30-b2a2-4065-93d8-2b15e91ad322.ckpt\n",
      "Restored all states from the checkpoint at /Users/hchen/gp-mjo/SINDy_RealData/experiments/.lr_find_9f99eb30-b2a2-4065-93d8-2b15e91ad322.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suggested learning rate: 0.1445439770745927\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# find optimal learning rate\n",
    "res = Tuner(trainer).lr_find(\n",
    "    net,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    "    min_lr=1e-6,\n",
    "    max_lr=1e0,\n",
    "    early_stop_threshold=100,\n",
    ")\n",
    "print(f\"suggested learning rate: {res.suggestion()}\")\n",
    "fig = res.plot(show=True, suggest=True)\n",
    "fig.show()\n",
    "net.hparams.learning_rate = res.suggestion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type                   | Params | Mode \n",
      "-------------------------------------------------------------------\n",
      "0 | loss            | NormalDistributionLoss | 0      | train\n",
      "1 | logging_metrics | ModuleList             | 0      | train\n",
      "2 | network         | FCNModule              | 14.6 K | train\n",
      "-------------------------------------------------------------------\n",
      "14.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "14.6 K    Total params\n",
      "0.058     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   4%|▍         | 2/50 [02:22<57:04,  0.01it/s, v_num=96, train_loss_step=7.27e+14]\n",
      "Epoch 2: 100%|██████████| 50/50 [03:21<00:00,  0.25it/s, v_num=98, train_loss_step=1.770, val_loss=1.430, train_loss_epoch=1.460]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 50/50 [03:21<00:00,  0.25it/s, v_num=98, train_loss_step=1.770, val_loss=1.430, train_loss_epoch=1.460]\n"
     ]
    }
   ],
   "source": [
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=10, verbose=False, mode=\"min\")\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=max_epochs,\n",
    "    accelerator=device,\n",
    "    enable_model_summary=True,\n",
    "    gradient_clip_val=0.1,\n",
    "    callbacks=[early_stop_callback],\n",
    "    limit_train_batches=50,\n",
    "    enable_checkpointing=True,\n",
    ")\n",
    "\n",
    "\n",
    "net = FCN.from_dataset(\n",
    "    training,\n",
    "    # learning_rate=res.suggestion(),\n",
    "    log_interval=10,\n",
    "    log_val_interval=1,\n",
    "    hidden_size=hidden_size,\n",
    "    n_hidden_layers=n_hidden_layers,\n",
    "    optimizer=\"Adam\",\n",
    "    loss=NormalDistributionLoss(),\n",
    ")\n",
    "\n",
    "trainer.fit(\n",
    "    net,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "best_model = FCN.load_from_checkpoint(best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# best_model = net\n",
    "predictions = best_model.predict(test_dataloader, mode=\"prediction\", \n",
    "                                trainer_kwargs=dict(accelerator=device), \n",
    "                                return_index=True, return_x=True, return_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "raw_predictions = net.predict(\n",
    "    test_dataloader, mode=\"raw\", \n",
    "    return_index=True, return_x=True, return_y=True, \n",
    "    n_samples=100, \n",
    "    trainer_kwargs=dict(accelerator=device)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1056, 60, 100])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_predictions.output[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.4858876   1.4127605   0.87013769  0.36032364 -0.2242689  -0.52937448\n",
      " -0.56909633 -0.33208254]\n",
      "[2.1454837 2.9190524 3.2660966 3.2806582 3.2044053 3.2006223 2.7466192\n",
      " 2.1816049]\n",
      "tensor([[ 1.4859,  1.4128,  0.8701,  0.3603, -0.2243, -0.5294, -0.5691, -0.3321],\n",
      "        [ 2.1455,  2.9191,  3.2661,  3.2807,  3.2044,  3.2006,  2.7466,  2.1816],\n",
      "        [ 1.4128,  0.8701,  0.3603, -0.2243, -0.5294, -0.5691, -0.3321, -0.0778],\n",
      "        [ 2.9191,  3.2661,  3.2807,  3.2044,  3.2006,  2.7466,  2.1816,  1.7408]])\n",
      "tensor([[ 0.6157,  0.5562,  0.2558,  0.6585,  0.5660,  0.0780,  0.3375,  0.0535],\n",
      "        [ 0.6736,  0.6732,  0.5957,  1.0690,  0.6387,  0.4163,  0.6208,  0.4220],\n",
      "        [ 0.5565,  0.5274,  0.2114,  0.4212,  0.4629, -0.0373,  0.1066, -0.1597],\n",
      "        [ 0.5997,  0.6609,  0.6632,  1.1282,  0.7291,  0.3404,  0.4386,  0.2999]])\n"
     ]
    }
   ],
   "source": [
    "print( entire_npzfile['RMM1'][start_forecast_test:start_forecast_test+8] )\n",
    "print( entire_npzfile['RMM2'][start_forecast_test:start_forecast_test+8] )\n",
    "print(raw_predictions.x['decoder_target'][:4, :8])\n",
    "print(raw_predictions.output[0].mean(dim=-1)[:4, :8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6956)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lead_time_id = 0\n",
    "RMSE()(raw_predictions.x['decoder_target'].squeeze()[:,lead_time_id][None,:], \n",
    "       raw_predictions.output[0].mean(dim=-1)[:,lead_time_id][None,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6963)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lead_time_id = 0\n",
    "RMSE()(predictions.x['decoder_target'][:,lead_time_id][:,None], \n",
    "       predictions.output[:,lead_time_id][:,None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "pl.seed_everything(42)\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=\"cpu\",\n",
    "    # clipping gradients is a hyperparameter and important to prevent divergance\n",
    "    # of the gradient for recurrent neural networks\n",
    "    gradient_clip_val=0.1,\n",
    ")\n",
    "\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    # not meaningful for finding the learning rate but otherwise very important\n",
    "    learning_rate=0.03,\n",
    "    hidden_size=8,  # most important hyperparameter apart from learning rate\n",
    "    # number of attention heads. Set to up to 4 for large datasets\n",
    "    attention_head_size=1,\n",
    "    dropout=0.1,  # between 0.1 and 0.3 are good values\n",
    "    hidden_continuous_size=8,  # set to <= hidden_size\n",
    "    loss=QuantileLoss(),\n",
    "    optimizer=\"Ranger\"\n",
    "    # reduce learning rate if no improvement in validation loss after x epochs\n",
    "    # reduce_on_plateau_patience=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = Tuner(trainer).lr_find(\n",
    "#     tft,\n",
    "#     train_dataloaders=train_dataloader,\n",
    "#     val_dataloaders=val_dataloader,\n",
    "#     max_lr=10.0,\n",
    "#     min_lr=1e-6,\n",
    "# )\n",
    "\n",
    "# print(f\"suggested learning rate: {res.suggestion()}\")\n",
    "# fig = res.plot(show=True, suggest=True)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n",
      "\n",
      "   | Name                               | Type                            | Params | Mode \n",
      "------------------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0      | train\n",
      "1  | logging_metrics                    | ModuleList                      | 0      | train\n",
      "2  | input_embeddings                   | MultiEmbedding                  | 2      | train\n",
      "3  | prescalers                         | ModuleDict                      | 16     | train\n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 48     | train\n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 528    | train\n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 0      | train\n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 1.1 K  | train\n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 1.1 K  | train\n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 1.1 K  | train\n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 1.1 K  | train\n",
      "11 | lstm_encoder                       | LSTM                            | 2.2 K  | train\n",
      "12 | lstm_decoder                       | LSTM                            | 2.2 K  | train\n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 544    | train\n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 32     | train\n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 1.4 K  | train\n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 808    | train\n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 576    | train\n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 1.1 K  | train\n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 576    | train\n",
      "20 | output_layer                       | Linear                          | 119    | train\n",
      "------------------------------------------------------------------------------------------------\n",
      "14.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "14.6 K    Total params\n",
      "0.058     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# configure network and trainer\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=10, verbose=False, mode=\"min\")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=50,\n",
    "    accelerator=\"cpu\",\n",
    "    enable_model_summary=True,\n",
    "    gradient_clip_val=0.1,\n",
    "    limit_train_batches=50,  # coment in for training, running valiation every 30 batches\n",
    "    fast_dev_run=True,  # comment in to check that networkor dataset has no serious bugs\n",
    "    callbacks=[early_stop_callback],\n",
    ")\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    learning_rate=0.03,\n",
    "    hidden_size=16,\n",
    "    attention_head_size=2,\n",
    "    dropout=0.1,\n",
    "    hidden_continuous_size=8,\n",
    "    loss=QuantileLoss(),\n",
    "    log_interval=10,  # uncomment for learning rate finder and otherwise, e.g. to 10 for logging every 10 batches\n",
    "    optimizer=\"Ranger\",\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "\n",
    "# fit network\n",
    "trainer.fit(\n",
    "    tft,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_gp_mjo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
