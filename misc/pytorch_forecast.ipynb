{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from typing import Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.tuner import Tuner\n",
    "from lightning.pytorch.callbacks import EarlyStopping\n",
    "\n",
    "import pytorch_forecasting as ptf\n",
    "from pytorch_forecasting import TimeSeriesDataSet, DeepAR, NHiTS, TemporalFusionTransformer, RecurrentNetwork, DecoderMLP\n",
    "from pytorch_forecasting.data import NaNLabelEncoder, TorchNormalizer, EncoderNormalizer\n",
    "from pytorch_forecasting.metrics import RMSE, NormalDistributionLoss, MultivariateNormalDistributionLoss, MQF2DistributionLoss, QuantileLoss\n",
    "from pytorch_forecasting.models import BaseModel\n",
    "\n",
    "from gp_mjo.utils.create_df import create_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['year', 'month', 'day', 'RMM1', 'RMM2', 'phase', 'amplitude']\n",
      "(16624,)\n"
     ]
    }
   ],
   "source": [
    "npzfile = np.load('../data/obs/mjo_new_data.npz', allow_pickle=True)\n",
    "print(npzfile.files)\n",
    "print(npzfile['RMM1'].shape)\n",
    "\n",
    "data_names = npzfile.files + ['id']\n",
    "n_files = len(data_names)\n",
    "\n",
    "entire_npzfile = {}\n",
    "for i, data_name in enumerate(data_names):\n",
    "    if i < n_files-1:\n",
    "        entire_npzfile[data_name] = npzfile[data_name]\n",
    "    if i == n_files-1:\n",
    "        entire_npzfile[data_name] = np.arange(len(npzfile['RMM1']))\n",
    "\n",
    "# Create the DataFrame using the function\n",
    "df = create_dataframe(entire_npzfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          value group  time_idx        date  phase  amplitude\n",
      "0      0.142507  RMM1         0  1979-01-01    6.0   1.060090\n",
      "1     -0.204200  RMM1         1  1979-01-02    7.0   1.388700\n",
      "2     -0.158610  RMM1         2  1979-01-03    7.0   1.547580\n",
      "3     -0.182450  RMM1         3  1979-01-04    7.0   1.471080\n",
      "4     -0.320050  RMM1         4  1979-01-05    7.0   1.181000\n",
      "...         ...   ...       ...         ...    ...        ...\n",
      "16619  0.386045  RMM1     16619  2024-07-02    3.0   1.455303\n",
      "16620  0.367469  RMM1     16620  2024-07-03    3.0   1.589958\n",
      "16621  0.209546  RMM1     16621  2024-07-04    3.0   1.466880\n",
      "16622  0.202304  RMM1     16622  2024-07-05    3.0   1.178915\n",
      "16623  0.412928  RMM1     16623  2024-07-06    3.0   1.128464\n",
      "\n",
      "[16624 rows x 6 columns]\n",
      "          value group  time_idx        date  phase  amplitude\n",
      "16624  1.050470  RMM2         0  1979-01-01    6.0   1.060090\n",
      "16625  1.373610  RMM2         1  1979-01-02    7.0   1.388700\n",
      "16626  1.539430  RMM2         2  1979-01-03    7.0   1.547580\n",
      "16627  1.459720  RMM2         3  1979-01-04    7.0   1.471080\n",
      "16628  1.136800  RMM2         4  1979-01-05    7.0   1.181000\n",
      "...         ...   ...       ...         ...    ...        ...\n",
      "33243 -1.403167  RMM2     16619  2024-07-02    3.0   1.455303\n",
      "33244 -1.546910  RMM2     16620  2024-07-03    3.0   1.589958\n",
      "33245 -1.451836  RMM2     16621  2024-07-04    3.0   1.466880\n",
      "33246 -1.161427  RMM2     16622  2024-07-05    3.0   1.178915\n",
      "33247 -1.050201  RMM2     16623  2024-07-06    3.0   1.128464\n",
      "\n",
      "[16624 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df[0:16624])\n",
    "\n",
    "print(df[16624:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset and dataloaders\n",
    "width = 40\n",
    "lead_time = 60\n",
    "n_pred = 528\n",
    "n = 10000\n",
    "v = 2000\n",
    "m = 5000\n",
    "start_train = 0\n",
    "n_offset = 0\n",
    "\n",
    "batch_size = 128\n",
    "seed = 99\n",
    "static_categoricals = []#['group'] #[] for 'NHiTS' 'FCNModel', ['group'] #as we plan to forecast correlations, it is important to use series characteristics (e.g. a series identifier)\n",
    "target_normalizer = None # None, TorchNormalizer(), EncoderNormalizer()\n",
    "\n",
    "training_cutoff = start_train + n + lead_time + width - 2 #df[\"time_idx\"].max() - lead_time\n",
    "\n",
    "start_forecast_val = training_cutoff + 1 + width # start_train + n + lead_time + n_offset \n",
    "validation_cutoff = start_forecast_val + v + lead_time - 2\n",
    "\n",
    "start_forecast_test = start_train + width + n + n_offset + width \\\n",
    "                + v + n_offset + 10 + width\n",
    "test_forecast_ids = np.arange( start_forecast_test, min( start_forecast_test + m, len(df) // 2 ) )\n",
    "test_cutoff = start_forecast_test + n_pred + lead_time - 2\n",
    "\n",
    "\n",
    "# create the dataset from the pandas dataframe\n",
    "training = TimeSeriesDataSet(\n",
    "    df[lambda x: x.time_idx <= training_cutoff],\n",
    "    target=\"value\",\n",
    "    time_idx=\"time_idx\",\n",
    "    group_ids=[\"group\"],\n",
    "    categorical_encoders={\"group\": NaNLabelEncoder().fit(df.group)},\n",
    "    static_categoricals = static_categoricals,\n",
    "    min_encoder_length=width,\n",
    "    max_encoder_length=width,\n",
    "    min_prediction_length=lead_time,\n",
    "    max_prediction_length=lead_time,\n",
    "    time_varying_unknown_reals=[\"value\"],\n",
    "    target_normalizer=target_normalizer,\n",
    ")\n",
    "\n",
    "\n",
    "validation = TimeSeriesDataSet(\n",
    "    df[lambda x: x.time_idx <= validation_cutoff],\n",
    "    target=\"value\",\n",
    "    time_idx=\"time_idx\",\n",
    "    group_ids=[\"group\"],\n",
    "    categorical_encoders={\"group\": NaNLabelEncoder().fit(df.group)},\n",
    "    static_categoricals = static_categoricals,\n",
    "    min_encoder_length=width,\n",
    "    max_encoder_length=width,\n",
    "    min_prediction_length=lead_time,\n",
    "    max_prediction_length=lead_time,\n",
    "    min_prediction_idx = start_forecast_val,\n",
    "    time_varying_unknown_reals=[\"value\"],\n",
    "    target_normalizer=target_normalizer,\n",
    ")\n",
    "\n",
    "test = TimeSeriesDataSet(\n",
    "    df[lambda x: x.time_idx <= test_cutoff],\n",
    "    target=\"value\",\n",
    "    time_idx=\"time_idx\",\n",
    "    group_ids=[\"group\"],\n",
    "    categorical_encoders={\"group\": NaNLabelEncoder().fit(df.group)},\n",
    "    static_categoricals = static_categoricals,\n",
    "    min_encoder_length=width,\n",
    "    max_encoder_length=width,\n",
    "    min_prediction_length=lead_time,\n",
    "    max_prediction_length=lead_time,\n",
    "    min_prediction_idx = start_forecast_test,\n",
    "    time_varying_unknown_reals=[\"value\"],\n",
    "    target_normalizer=target_normalizer,\n",
    ")\n",
    "\n",
    "# synchronize samples in each batch over time - only necessary for DeepVAR, not for DeepAR\n",
    "train_dataloader = training.to_dataloader(\n",
    "    train=True, batch_size=batch_size, num_workers=0, batch_sampler=\"synchronized\",\n",
    "    shuffle=True, generator=torch.Generator().manual_seed(seed),\n",
    ")\n",
    "val_dataloader = validation.to_dataloader(\n",
    "    train=False, batch_size=batch_size, num_workers=0, batch_sampler=\"synchronized\",\n",
    "    shuffle=True, generator=torch.Generator().manual_seed(seed),\n",
    ")\n",
    "test_dataloader = test.to_dataloader(\n",
    "    train=False, batch_size=batch_size, num_workers=0, batch_sampler=\"synchronized\",\n",
    "    shuffle=True, generator=torch.Generator().manual_seed(seed),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeSeriesDataSet[length=20000](\n",
      "\ttime_idx='time_idx',\n",
      "\ttarget='value',\n",
      "\tgroup_ids=['group'],\n",
      "\tweight=None,\n",
      "\tmax_encoder_length=40,\n",
      "\tmin_encoder_length=40,\n",
      "\tmin_prediction_idx=0,\n",
      "\tmin_prediction_length=60,\n",
      "\tmax_prediction_length=60,\n",
      "\tstatic_categoricals=[],\n",
      "\tstatic_reals=[],\n",
      "\ttime_varying_known_categoricals=[],\n",
      "\ttime_varying_known_reals=[],\n",
      "\ttime_varying_unknown_categoricals=[],\n",
      "\ttime_varying_unknown_reals=['value'],\n",
      "\tvariable_groups={},\n",
      "\tconstant_fill_strategy={},\n",
      "\tallow_missing_timesteps=False,\n",
      "\tlags={},\n",
      "\tadd_relative_time_idx=False,\n",
      "\tadd_target_scales=False,\n",
      "\tadd_encoder_length=False,\n",
      "\ttarget_normalizer=TorchNormalizer(method='identity', center=True, transformation=None, method_kwargs={}),\n",
      "\tcategorical_encoders={'group': NaNLabelEncoder(add_nan=False, warn=True), '__group_id__group': NaNLabelEncoder(add_nan=False, warn=True)},\n",
      "\tscalers={},\n",
      "\trandomize_length=None,\n",
      "\tpredict_mode=False\n",
      ")\n",
      "TimeSeriesDataSet[length=4000](\n",
      "\ttime_idx='time_idx',\n",
      "\ttarget='value',\n",
      "\tgroup_ids=['group'],\n",
      "\tweight=None,\n",
      "\tmax_encoder_length=40,\n",
      "\tmin_encoder_length=40,\n",
      "\tmin_prediction_idx=10139,\n",
      "\tmin_prediction_length=60,\n",
      "\tmax_prediction_length=60,\n",
      "\tstatic_categoricals=[],\n",
      "\tstatic_reals=[],\n",
      "\ttime_varying_known_categoricals=[],\n",
      "\ttime_varying_known_reals=[],\n",
      "\ttime_varying_unknown_categoricals=[],\n",
      "\ttime_varying_unknown_reals=['value'],\n",
      "\tvariable_groups={},\n",
      "\tconstant_fill_strategy={},\n",
      "\tallow_missing_timesteps=False,\n",
      "\tlags={},\n",
      "\tadd_relative_time_idx=False,\n",
      "\tadd_target_scales=False,\n",
      "\tadd_encoder_length=False,\n",
      "\ttarget_normalizer=TorchNormalizer(method='identity', center=True, transformation=None, method_kwargs={}),\n",
      "\tcategorical_encoders={'group': NaNLabelEncoder(add_nan=False, warn=True), '__group_id__group': NaNLabelEncoder(add_nan=False, warn=True)},\n",
      "\tscalers={},\n",
      "\trandomize_length=None,\n",
      "\tpredict_mode=False\n",
      ")\n",
      "TimeSeriesDataSet[length=1056](\n",
      "\ttime_idx='time_idx',\n",
      "\ttarget='value',\n",
      "\tgroup_ids=['group'],\n",
      "\tweight=None,\n",
      "\tmax_encoder_length=40,\n",
      "\tmin_encoder_length=40,\n",
      "\tmin_prediction_idx=12130,\n",
      "\tmin_prediction_length=60,\n",
      "\tmax_prediction_length=60,\n",
      "\tstatic_categoricals=[],\n",
      "\tstatic_reals=[],\n",
      "\ttime_varying_known_categoricals=[],\n",
      "\ttime_varying_known_reals=[],\n",
      "\ttime_varying_unknown_categoricals=[],\n",
      "\ttime_varying_unknown_reals=['value'],\n",
      "\tvariable_groups={},\n",
      "\tconstant_fill_strategy={},\n",
      "\tallow_missing_timesteps=False,\n",
      "\tlags={},\n",
      "\tadd_relative_time_idx=False,\n",
      "\tadd_target_scales=False,\n",
      "\tadd_encoder_length=False,\n",
      "\ttarget_normalizer=TorchNormalizer(method='identity', center=True, transformation=None, method_kwargs={}),\n",
      "\tcategorical_encoders={'group': NaNLabelEncoder(add_nan=False, warn=True), '__group_id__group': NaNLabelEncoder(add_nan=False, warn=True)},\n",
      "\tscalers={},\n",
      "\trandomize_length=None,\n",
      "\tpredict_mode=False\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print( train_dataloader.dataset )\n",
    "print( val_dataloader.dataset )\n",
    "print( test_dataloader.dataset )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 99\n"
     ]
    }
   ],
   "source": [
    "device = \"cpu\" #[\"cpu\", \"mps\", \"cuda\", \"tpu\", \"hpu\"]\n",
    "pl.seed_everything(seed)\n",
    "\n",
    "hidden_size = 64\n",
    "lr = 3e-2\n",
    "rnn_layers = 1\n",
    "max_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(accelerator=\"cpu\", gradient_clip_val=1e-1)\n",
    "net = DeepAR.from_dataset(\n",
    "    training,\n",
    "    learning_rate=lr,\n",
    "    hidden_size=hidden_size,\n",
    "    rnn_layers=rnn_layers,\n",
    "    loss=MultivariateNormalDistributionLoss(rank=30),\n",
    "    optimizer=\"Adam\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding best initial lr:  97%|█████████▋| 97/100 [00:02<00:00, 49.47it/s]`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Finding best initial lr: 100%|██████████| 100/100 [00:02<00:00, 45.05it/s]\n",
      "Learning rate set to 0.03548133892335753\n",
      "Restoring states from the checkpoint path at /Users/hchen/gp-mjo/SINDy_RealData/experiments/.lr_find_9ca86000-bd28-4424-825f-853a869aa33d.ckpt\n",
      "Restored all states from the checkpoint at /Users/hchen/gp-mjo/SINDy_RealData/experiments/.lr_find_9ca86000-bd28-4424-825f-853a869aa33d.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suggested learning rate: 0.03548133892335753\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# find optimal learning rate\n",
    "res = Tuner(trainer).lr_find(\n",
    "    net,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    "    min_lr=1e-5,\n",
    "    max_lr=1e0,\n",
    "    early_stop_threshold=100,\n",
    ")\n",
    "print(f\"suggested learning rate: {res.suggestion()}\")\n",
    "fig = res.plot(show=True, suggest=True)\n",
    "fig.show()\n",
    "net.hparams.learning_rate = res.suggestion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name                   | Type                               | Params | Mode \n",
      "--------------------------------------------------------------------------------------\n",
      "0 | loss                   | MultivariateNormalDistributionLoss | 0      | train\n",
      "1 | logging_metrics        | ModuleList                         | 0      | train\n",
      "2 | embeddings             | MultiEmbedding                     | 0      | train\n",
      "3 | rnn                    | LSTM                               | 17.2 K | train\n",
      "4 | distribution_projector | Linear                             | 2.1 K  | train\n",
      "--------------------------------------------------------------------------------------\n",
      "19.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "19.2 K    Total params\n",
      "0.077     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 50/50 [00:01<00:00, 28.88it/s, v_num=115, train_loss_step=-0.436]  "
     ]
    }
   ],
   "source": [
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=10, verbose=False, mode=\"min\")\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=max_epochs,\n",
    "    accelerator=device,\n",
    "    enable_model_summary=True,\n",
    "    gradient_clip_val=0.1,\n",
    "    callbacks=[early_stop_callback],\n",
    "    limit_train_batches=50,\n",
    "    enable_checkpointing=True,\n",
    ")\n",
    "\n",
    "\n",
    "net = DeepAR.from_dataset(\n",
    "    training,\n",
    "    learning_rate=res.suggestion(),\n",
    "    log_interval=10,\n",
    "    log_val_interval=1,\n",
    "    hidden_size=hidden_size,\n",
    "    rnn_layers=rnn_layers,\n",
    "    optimizer=\"Adam\",\n",
    "    loss=MultivariateNormalDistributionLoss(rank=30),\n",
    ")\n",
    "\n",
    "trainer.fit(\n",
    "    net,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "best_model = DeepAR.load_from_checkpoint(best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# best_model = net\n",
    "predictions = best_model.predict(test_dataloader, mode=\"prediction\", \n",
    "                                trainer_kwargs=dict(accelerator=device), \n",
    "                                return_index=True, return_x=True, return_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "raw_predictions = net.predict(\n",
    "    test_dataloader, mode=\"raw\", \n",
    "    return_index=True, return_x=True, return_y=True, \n",
    "    n_samples=100, \n",
    "    trainer_kwargs=dict(accelerator=device)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1056, 60])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.x['decoder_target'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        True\n",
       "1       False\n",
       "2        True\n",
       "3       False\n",
       "4        True\n",
       "        ...  \n",
       "1051    False\n",
       "1052     True\n",
       "1053    False\n",
       "1054     True\n",
       "1055    False\n",
       "Name: group, Length: 1056, dtype: bool"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.index.group == 'RMM1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1056, 60, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_predictions.x['decoder_cont'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1056, 60])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_predictions.output[0].mean(dim=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.4858876 ,  1.4127605 ,  0.87013769,  0.36032364, -0.2242689 ,\n",
       "       -0.52937448, -0.56909633, -0.33208254])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entire_npzfile['RMM1'][start_forecast_test:start_forecast_test+8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.4859,  1.4128,  0.8701,  0.3603, -0.2243, -0.5294, -0.5691, -0.3321],\n",
      "        [ 2.1455,  2.9191,  3.2661,  3.2807,  3.2044,  3.2006,  2.7466,  2.1816],\n",
      "        [ 1.4128,  0.8701,  0.3603, -0.2243, -0.5294, -0.5691, -0.3321, -0.0778],\n",
      "        [ 2.9191,  3.2661,  3.2807,  3.2044,  3.2006,  2.7466,  2.1816,  1.7408]])\n",
      "tensor([[ 1.2471,  1.0196,  0.8272,  0.6206,  0.4258,  0.2958,  0.1818,  0.0432],\n",
      "        [ 1.6097,  1.2548,  0.8414,  0.4869,  0.2285, -0.0423, -0.2731, -0.4182],\n",
      "        [ 1.3870,  1.1560,  0.9537,  0.7165,  0.4707,  0.4230,  0.4124,  0.3936],\n",
      "        [ 2.1169,  1.6341,  1.1657,  0.7380,  0.3770,  0.0779, -0.2109, -0.3979]])\n"
     ]
    }
   ],
   "source": [
    "print(raw_predictions.x['decoder_target'][:4, :8])\n",
    "print(raw_predictions.output[0].mean(dim=-1)[:4, :8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7566)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lead_time_id = 0\n",
    "RMSE()(raw_predictions.x['decoder_cont'].squeeze()[:,lead_time_id][None,:], \n",
    "       raw_predictions.output[0].mean(dim=-1)[:,lead_time_id][None,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7560)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lead_time_id = 0\n",
    "RMSE()(predictions.x['decoder_cont'].squeeze()[:,lead_time_id][:,None], \n",
    "       predictions.output[:,lead_time_id][:,None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1056, 60])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.4239,  1.3409,  1.2561,  ..., -1.7521, -1.6877, -1.6196],\n",
       "        [ 1.4632,  1.4088,  1.3061,  ..., -1.8059, -1.7711, -1.7460],\n",
       "        [ 1.3893,  1.3717,  1.2565,  ..., -2.0053, -1.9316, -1.9248],\n",
       "        ...,\n",
       "        [-1.5626, -1.8241, -2.0137,  ..., -1.9796, -1.9755, -1.9901],\n",
       "        [-1.3055, -1.4449, -1.5756,  ..., -1.8870, -1.8625, -1.8465],\n",
       "        [-1.4148, -1.5460, -1.6694,  ..., -1.8822, -1.8896, -1.8480]])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.output[predictions.index.group == 'RMM1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([528, 60, 100])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_predictions.output[0][raw_predictions.index.group == 'RMM1'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.4239, 1.3409, 1.2561, 1.1243, 0.9648, 0.8177, 0.6118, 0.3598],\n",
       "        [1.4632, 1.4088, 1.3061, 1.1830, 1.0075, 0.8025, 0.6483, 0.4598],\n",
       "        [1.3893, 1.3717, 1.2565, 1.1139, 0.9733, 0.8386, 0.6476, 0.4889]])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.output[(0,2,4),:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.4859,  1.4128,  0.8701,  0.3603, -0.2243, -0.5294, -0.5691, -0.3321],\n",
       "        [ 1.4128,  0.8701,  0.3603, -0.2243, -0.5294, -0.5691, -0.3321, -0.0778],\n",
       "        [ 0.8701,  0.3603, -0.2243, -0.5294, -0.5691, -0.3321, -0.0778,  0.1272]])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.x['decoder_target'][predictions.index.group == 'RMM1'][:3,:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.4858876 ,  1.4127605 ,  0.87013769,  0.36032364, -0.2242689 ,\n",
       "       -0.52937448, -0.56909633, -0.33208254, -0.07775909,  0.12718512,\n",
       "        0.12812702])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entire_npzfile['RMM1'][start_forecast_test:start_forecast_test+11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NHiTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 99\n"
     ]
    }
   ],
   "source": [
    "device = \"cpu\" #[\"cpu\", \"mps\", \"cuda\", \"tpu\", \"hpu\"]\n",
    "pl.seed_everything(seed)\n",
    "\n",
    "hidden_size = 64\n",
    "lr = 3e-2\n",
    "rnn_layers = 1\n",
    "max_epochs = 5\n",
    "\n",
    "weight_decay = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 99\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "pl.seed_everything(seed)\n",
    "trainer = pl.Trainer(accelerator=device, gradient_clip_val=0.1)\n",
    "net = NHiTS.from_dataset(\n",
    "    training,\n",
    "    learning_rate=lr,\n",
    "    weight_decay=weight_decay,\n",
    "    loss=MQF2DistributionLoss(prediction_length=lead_time),\n",
    "    backcast_loss_ratio=0.0,\n",
    "    hidden_size=hidden_size,\n",
    "    optimizer=\"AdamW\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "free variable 'encoder_features' referenced before assignment in enclosing scope",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# find optimal learning rate\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mTuner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr_find\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_lr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_lr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-1\u001b[39;49m\n\u001b[1;32m      4\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msuggested learning rate: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mres\u001b[38;5;241m.\u001b[39msuggestion()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m fig \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39mplot(show\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, suggest\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/gp-mjo/SINDy_RealData/env_gp_mjo/lib/python3.9/site-packages/lightning/pytorch/tuner/tuning.py:180\u001b[0m, in \u001b[0;36mTuner.lr_find\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, dataloaders, datamodule, method, min_lr, max_lr, num_training, mode, early_stop_threshold, update_attr, attr_name)\u001b[0m\n\u001b[1;32m    177\u001b[0m lr_finder_callback\u001b[38;5;241m.\u001b[39m_early_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer\u001b[38;5;241m.\u001b[39mcallbacks \u001b[38;5;241m=\u001b[39m [lr_finder_callback] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer\u001b[38;5;241m.\u001b[39mcallbacks\n\u001b[0;32m--> 180\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer\u001b[38;5;241m.\u001b[39mcallbacks \u001b[38;5;241m=\u001b[39m [cb \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer\u001b[38;5;241m.\u001b[39mcallbacks \u001b[38;5;28;01mif\u001b[39;00m cb \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lr_finder_callback]\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m lr_finder_callback\u001b[38;5;241m.\u001b[39moptimal_lr\n",
      "File \u001b[0;32m~/gp-mjo/SINDy_RealData/env_gp_mjo/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py:543\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 543\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/gp-mjo/SINDy_RealData/env_gp_mjo/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/gp-mjo/SINDy_RealData/env_gp_mjo/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py:579\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    573\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    574\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    575\u001b[0m     ckpt_path,\n\u001b[1;32m    576\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    577\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    578\u001b[0m )\n\u001b[0;32m--> 579\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    581\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/gp-mjo/SINDy_RealData/env_gp_mjo/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py:966\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[38;5;66;03m# hook\u001b[39;00m\n\u001b[1;32m    965\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;241m==\u001b[39m TrainerFn\u001b[38;5;241m.\u001b[39mFITTING:\n\u001b[0;32m--> 966\u001b[0m     \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_callback_hooks\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mon_fit_start\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    967\u001b[0m     call\u001b[38;5;241m.\u001b[39m_call_lightning_module_hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_fit_start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    969\u001b[0m _log_hyperparams(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/gp-mjo/SINDy_RealData/env_gp_mjo/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py:210\u001b[0m, in \u001b[0;36m_call_callback_hooks\u001b[0;34m(trainer, hook_name, monitoring_callbacks, *args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(fn):\n\u001b[1;32m    209\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Callback]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcallback\u001b[38;5;241m.\u001b[39mstate_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 210\u001b[0m             \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pl_module:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/gp-mjo/SINDy_RealData/env_gp_mjo/lib/python3.9/site-packages/lightning/pytorch/callbacks/lr_finder.py:130\u001b[0m, in \u001b[0;36mLearningRateFinder.on_fit_start\u001b[0;34m(self, trainer, pl_module)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_fit_start\u001b[39m(\u001b[38;5;28mself\u001b[39m, trainer: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpl.Trainer\u001b[39m\u001b[38;5;124m\"\u001b[39m, pl_module: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpl.LightningModule\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 130\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr_find\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpl_module\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/gp-mjo/SINDy_RealData/env_gp_mjo/lib/python3.9/site-packages/lightning/pytorch/callbacks/lr_finder.py:113\u001b[0m, in \u001b[0;36mLearningRateFinder.lr_find\u001b[0;34m(self, trainer, pl_module)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlr_find\u001b[39m(\u001b[38;5;28mself\u001b[39m, trainer: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpl.Trainer\u001b[39m\u001b[38;5;124m\"\u001b[39m, pl_module: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpl.LightningModule\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n\u001b[0;32m--> 113\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimal_lr \u001b[38;5;241m=\u001b[39m \u001b[43m_lr_find\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpl_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmin_lr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_min_lr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_lr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_max_lr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_training\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_training_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m            \u001b[49m\u001b[43mearly_stop_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_early_stop_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m            \u001b[49m\u001b[43mupdate_attr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_attr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m            \u001b[49m\u001b[43mattr_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_attr_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_early_exit:\n\u001b[1;32m    126\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m _TunerExitException()\n",
      "File \u001b[0;32m~/gp-mjo/SINDy_RealData/env_gp_mjo/lib/python3.9/site-packages/lightning/pytorch/tuner/lr_finder.py:275\u001b[0m, in \u001b[0;36m_lr_find\u001b[0;34m(trainer, model, min_lr, max_lr, num_training, mode, early_stop_threshold, update_attr, attr_name)\u001b[0m\n\u001b[1;32m    272\u001b[0m lr_finder\u001b[38;5;241m.\u001b[39m_exchange_scheduler(trainer)\n\u001b[1;32m    274\u001b[0m \u001b[38;5;66;03m# Fit, lr & loss logged in callback\u001b[39;00m\n\u001b[0;32m--> 275\u001b[0m \u001b[43m_try_loop_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;66;03m# Prompt if we stopped early\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m!=\u001b[39m num_training \u001b[38;5;241m+\u001b[39m start_steps:\n",
      "File \u001b[0;32m~/gp-mjo/SINDy_RealData/env_gp_mjo/lib/python3.9/site-packages/lightning/pytorch/tuner/lr_finder.py:520\u001b[0m, in \u001b[0;36m_try_loop_run\u001b[0;34m(trainer, params)\u001b[0m\n\u001b[1;32m    518\u001b[0m loop\u001b[38;5;241m.\u001b[39mload_state_dict(deepcopy(params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloop_state_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[1;32m    519\u001b[0m loop\u001b[38;5;241m.\u001b[39mrestarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 520\u001b[0m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/gp-mjo/SINDy_RealData/env_gp_mjo/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py:205\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start()\n\u001b[0;32m--> 205\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/gp-mjo/SINDy_RealData/env_gp_mjo/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py:363\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_training_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 363\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/gp-mjo/SINDy_RealData/env_gp_mjo/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py:141\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madvance(data_fetcher)\n\u001b[0;32m--> 141\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_advance_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "File \u001b[0;32m~/gp-mjo/SINDy_RealData/env_gp_mjo/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py:295\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.on_advance_end\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_accumulate():\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;66;03m# clear gradients to not leave any unused memory during validation\u001b[39;00m\n\u001b[1;32m    293\u001b[0m     call\u001b[38;5;241m.\u001b[39m_call_lightning_module_hook(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_validation_model_zero_grad\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 295\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39m_logger_connector\u001b[38;5;241m.\u001b[39m_first_loop_iter \u001b[38;5;241m=\u001b[39m first_loop_iter\n",
      "File \u001b[0;32m~/gp-mjo/SINDy_RealData/env_gp_mjo/lib/python3.9/site-packages/lightning/pytorch/loops/utilities.py:182\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m     context_manager \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mno_grad\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[0;32m--> 182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/gp-mjo/SINDy_RealData/env_gp_mjo/lib/python3.9/site-packages/lightning/pytorch/loops/evaluation_loop.py:135\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mis_last_batch \u001b[38;5;241m=\u001b[39m data_fetcher\u001b[38;5;241m.\u001b[39mdone\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;66;03m# run step hooks\u001b[39;00m\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;66;03m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[39;00m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/gp-mjo/SINDy_RealData/env_gp_mjo/lib/python3.9/site-packages/lightning/pytorch/loops/evaluation_loop.py:396\u001b[0m, in \u001b[0;36m_EvaluationLoop._evaluation_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx, dataloader_iter)\u001b[0m\n\u001b[1;32m    390\u001b[0m hook_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_step\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mtesting \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    391\u001b[0m step_args \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_step_args_from_hook_kwargs(hook_kwargs, hook_name)\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_dataloader_iter\n\u001b[1;32m    394\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m (dataloader_iter,)\n\u001b[1;32m    395\u001b[0m )\n\u001b[0;32m--> 396\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstep_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_processed()\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m using_dataloader_iter:\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;66;03m# update the hook kwargs now that the step method might have consumed the iterator\u001b[39;00m\n",
      "File \u001b[0;32m~/gp-mjo/SINDy_RealData/env_gp_mjo/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py:311\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 311\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    314\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/gp-mjo/SINDy_RealData/env_gp_mjo/lib/python3.9/site-packages/lightning/pytorch/strategies/strategy.py:411\u001b[0m, in \u001b[0;36mStrategy.validation_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module:\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_redirection(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 411\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/gp-mjo/SINDy_RealData/env_gp_mjo/lib/python3.9/site-packages/pytorch_forecasting/models/base_model.py:630\u001b[0m, in \u001b[0;36mBaseModel.validation_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidation_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, batch_idx):\n\u001b[1;32m    629\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m batch\n\u001b[0;32m--> 630\u001b[0m     log, out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m     log\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_log(x, y, out, batch_idx))\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidation_step_outputs\u001b[38;5;241m.\u001b[39mappend(log)\n",
      "File \u001b[0;32m~/gp-mjo/SINDy_RealData/env_gp_mjo/lib/python3.9/site-packages/pytorch_forecasting/models/nhits/__init__.py:354\u001b[0m, in \u001b[0;36mNHiTS.step\u001b[0;34m(self, x, y, batch_idx)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, y, batch_idx) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    351\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;124;03m    Take training / validation step.\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 354\u001b[0m     log, out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    356\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhparams\u001b[38;5;241m.\u001b[39mbackcast_loss_ratio \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredicting:  \u001b[38;5;66;03m# add loss from backcast\u001b[39;00m\n\u001b[1;32m    357\u001b[0m         backcast \u001b[38;5;241m=\u001b[39m out[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbackcast\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/gp-mjo/SINDy_RealData/env_gp_mjo/lib/python3.9/site-packages/pytorch_forecasting/models/base_model.py:777\u001b[0m, in \u001b[0;36mBaseModel.step\u001b[0;34m(self, x, y, batch_idx, **kwargs)\u001b[0m\n\u001b[1;32m    775\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 777\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;66;03m# calculate loss\u001b[39;00m\n\u001b[1;32m    780\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m out[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/gp-mjo/SINDy_RealData/env_gp_mjo/lib/python3.9/site-packages/torch/nn/modules/module.py:1657\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1657\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/gp-mjo/SINDy_RealData/env_gp_mjo/lib/python3.9/site-packages/torch/nn/modules/module.py:1668\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1664\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1665\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1666\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1667\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1668\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1670\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1671\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/gp-mjo/SINDy_RealData/env_gp_mjo/lib/python3.9/site-packages/pytorch_forecasting/models/nhits/__init__.py:256\u001b[0m, in \u001b[0;36mNHiTS.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;66;03m# statics\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatic_size \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 256\u001b[0m     x_s \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mconcat([encoder_features[name][:, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatic_variables], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     x_s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/gp-mjo/SINDy_RealData/env_gp_mjo/lib/python3.9/site-packages/pytorch_forecasting/models/nhits/__init__.py:256\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;66;03m# statics\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatic_size \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 256\u001b[0m     x_s \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mconcat([\u001b[43mencoder_features\u001b[49m[name][:, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatic_variables], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     x_s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: free variable 'encoder_features' referenced before assignment in enclosing scope"
     ]
    }
   ],
   "source": [
    "# find optimal learning rate\n",
    "res = Tuner(trainer).lr_find(\n",
    "    net, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader, min_lr=1e-5, max_lr=1e-1\n",
    ")\n",
    "print(f\"suggested learning rate: {res.suggestion()}\")\n",
    "fig = res.plot(show=True, suggest=True)\n",
    "fig.show()\n",
    "net.hparams.learning_rate = res.suggestion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_clip_val = 0.1\n",
    "limit_train_batches = 30 # 50 for DeepVAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type                 | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0 | loss            | MQF2DistributionLoss | 11.7 K | train\n",
      "1 | logging_metrics | ModuleList           | 0      | train\n",
      "2 | embeddings      | MultiEmbedding       | 0      | train\n",
      "3 | model           | NHiTS                | 39.9 K | train\n",
      "-----------------------------------------------------------------\n",
      "51.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "51.5 K    Total params\n",
      "0.206     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 30/30 [00:02<00:00, 10.18it/s, v_num=31, train_loss_step=0.123, val_loss=0.0943, train_loss_epoch=0.0896] "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=10, verbose=False, mode=\"min\")\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=max_epochs,\n",
    "    accelerator=device,\n",
    "    enable_model_summary=True,\n",
    "    gradient_clip_val=gradient_clip_val,\n",
    "    callbacks=[early_stop_callback],\n",
    "    limit_train_batches=limit_train_batches,\n",
    "    enable_checkpointing=True,\n",
    ")\n",
    "\n",
    "\n",
    "net = NHiTS.from_dataset(\n",
    "    training,\n",
    "    learning_rate=res.suggestion(),\n",
    "    log_interval=10,\n",
    "    log_val_interval=1,\n",
    "    weight_decay=weight_decay,\n",
    "    backcast_loss_ratio=0.0,\n",
    "    hidden_size=hidden_size,\n",
    "    optimizer=\"AdamW\",\n",
    "    loss=MQF2DistributionLoss(prediction_length=lead_time),\n",
    ")\n",
    "\n",
    "trainer.fit(\n",
    "    net,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "best_model = NHiTS.load_from_checkpoint(best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model = net\n",
    "predictions = best_model.predict(test_dataloader, mode=\"prediction\", \n",
    "                        trainer_kwargs=dict(accelerator=device), \n",
    "                        return_index=True, return_x=True, return_y=True)\n",
    "\n",
    "raw_predictions = net.predict(\n",
    "    test_dataloader, mode=\"raw\", \n",
    "    return_index=True, return_x=True, return_y=True, \n",
    "    n_samples=100, \n",
    "    trainer_kwargs=dict(accelerator=device)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_time_id = 0\n",
    "RMSE()(predictions.x['decoder_target'][:,lead_time_id][:,None], \n",
    "       predictions.output[:,lead_time_id][:,None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_time_id = 0\n",
    "RMSE()(raw_predictions.x['decoder_target'][:,lead_time_id][None,:], \n",
    "       raw_predictions.output[0].mean(dim=-1)[:,lead_time_id][None,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUModule(nn.Module):\n",
    "    def __init__(self, input_size: int, output_size: int, hidden_size: int, \n",
    "                rnn_layers: int, sequence_length: int, n_outputs: int):\n",
    "        super(GRUModule, self).__init__()\n",
    "        self.hidden_size  = hidden_size\n",
    "        self.rnn_layers = rnn_layers\n",
    "        self.sequence_length = sequence_length\n",
    "        self.n_outputs = n_outputs\n",
    "        \n",
    "        self.gru = nn.GRU(input_size, hidden_size, rnn_layers, \n",
    "                        batch_first=True, bidirectional=False)\n",
    "        self.fc1 = nn.Linear(hidden_size * sequence_length, output_size)\n",
    "\n",
    "        module_list = []\n",
    "        module_list.append(nn.Linear(hidden_size * sequence_length, output_size * n_outputs))\n",
    "        self.fc = nn.Sequential(*module_list)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # x is of size [batch_size, sequence_length, input_size]\n",
    "        h0 = torch.zeros(self.rnn_layers, x.size(0), self.hidden_size, device=x.device)\n",
    "\n",
    "\n",
    "        out,_ = self.gru(x, h0) # [batch_size, sequence_length, hidden_size]\n",
    "        # Reshaping the outputs in the shape of (batch_size, seq_length, hidden_size)\n",
    "        # so that it can fit into the fully connected layer\n",
    "        # out = out[:, -1, :]\n",
    "        out = out.reshape(out.shape[0], -1)\n",
    "        out = self.fc(out)\n",
    "\n",
    "        out = out.reshape(out.shape[0], -1, self.n_outputs)\n",
    "        return out\n",
    "\n",
    "input_size = 20\n",
    "output_size = 60\n",
    "hidden_size = 8\n",
    "rnn_layers = 1\n",
    "sequence_length = 1\n",
    "batch_size = 32\n",
    "\n",
    "torch.manual_seed(0)\n",
    "input = torch.randn(batch_size, sequence_length, input_size)\n",
    "\n",
    "model = GRUModule(input_size=input_size, output_size=output_size, hidden_size=hidden_size, \n",
    "                rnn_layers=rnn_layers, sequence_length=sequence_length, n_outputs=2)\n",
    "\n",
    "out = model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"hidden_size\":                 10\n",
       "\"input_size\":                  1\n",
       "\"learning_rate\":               0.001\n",
       "\"log_gradient_flow\":           False\n",
       "\"log_interval\":                -1\n",
       "\"log_val_interval\":            -1\n",
       "\"logging_metrics\":             ModuleList()\n",
       "\"monotone_constaints\":         {}\n",
       "\"optimizer\":                   Ranger\n",
       "\"optimizer_params\":            None\n",
       "\"output_size\":                 60\n",
       "\"output_transformer\":          TorchNormalizer(method='identity', center=True, transformation=None, method_kwargs={})\n",
       "\"reduce_on_plateau_min_lr\":    1e-05\n",
       "\"reduce_on_plateau_patience\":  1000\n",
       "\"reduce_on_plateau_reduction\": 2.0\n",
       "\"rnn_layers\":                  1\n",
       "\"sequence_length\":             40\n",
       "\"weight_decay\":                0.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class GRU(BaseModel):  # we inherit the `from_dataset` method\n",
    "    def __init__(self, input_size: int, output_size: int, hidden_size: int, \n",
    "                rnn_layers: int, sequence_length: int, **kwargs):\n",
    "        # saves arguments in signature to `.hparams` attribute, mandatory call - do not skip this\n",
    "        self.save_hyperparameters()\n",
    "        # pass additional arguments to BaseModel.__init__, mandatory call - do not skip this\n",
    "        super().__init__(**kwargs)\n",
    "        self.network = GRUModule(\n",
    "            input_size=self.hparams.input_size,\n",
    "            output_size=self.hparams.output_size,\n",
    "            hidden_size=self.hparams.hidden_size,\n",
    "            rnn_layers=self.hparams.rnn_layers,\n",
    "            sequence_length=self.hparams.sequence_length,\n",
    "            n_outputs=2,  # <<<<<<<< we predict two outputs for mean and scale of the normal distribution\n",
    "        )\n",
    "        self.loss = NormalDistributionLoss()\n",
    "\n",
    "    @classmethod\n",
    "    def from_dataset(cls, dataset: TimeSeriesDataSet, **kwargs):\n",
    "        new_kwargs = {\n",
    "            \"output_size\": dataset.max_prediction_length,\n",
    "            # \"input_size\": dataset.max_encoder_length,\n",
    "            # \"sequence_length\": dataset.max_encoder_length,\n",
    "        }\n",
    "        new_kwargs.update(kwargs)  # use to pass real hyperparameters and override defaults set by dataset\n",
    "        # example for dataset validation\n",
    "        assert dataset.max_prediction_length == dataset.min_prediction_length, \"Decoder only supports a fixed length\"\n",
    "        assert dataset.min_encoder_length == dataset.max_encoder_length, \"Encoder only supports a fixed length\"\n",
    "        assert (\n",
    "            len(dataset.time_varying_known_categoricals) == 0\n",
    "            and len(dataset.time_varying_known_reals) == 0\n",
    "            and len(dataset.time_varying_unknown_categoricals) == 0\n",
    "            and len(dataset.static_categoricals) == 0\n",
    "            and len(dataset.static_reals) == 0\n",
    "            and len(dataset.time_varying_unknown_reals) == 1\n",
    "            and dataset.time_varying_unknown_reals[0] == dataset.target\n",
    "        ), \"Only covariate should be the target in 'time_varying_unknown_reals'\"\n",
    "\n",
    "        return super().from_dataset(dataset, **new_kwargs)\n",
    "\n",
    "    def forward(self, x: Dict[str, torch.Tensor], n_samples: int = None) -> Dict[str, torch.Tensor]:\n",
    "        # x is a batch generated based on the TimeSeriesDataset\n",
    "        network_input = x[\"encoder_cont\"]\n",
    "        prediction = self.network(network_input)  # shape batch_size x n_decoder_steps x 2\n",
    "        # we need to scale the parameters to real space\n",
    "        prediction = self.transform_output(\n",
    "            prediction=prediction,\n",
    "            target_scale=x[\"target_scale\"],\n",
    "        )\n",
    "        if n_samples is not None:\n",
    "            # sample from distribution\n",
    "            prediction = self.loss.sample(prediction, n_samples)\n",
    "        # The conversion to a named tuple can be directly achieved with the `to_network_output` function.\n",
    "        return self.to_network_output(prediction=prediction)\n",
    "\n",
    "\n",
    "model = GRU.from_dataset(training, hidden_size=10, rnn_layers=1, \n",
    "                        input_size=1, sequence_length=width)\n",
    "model.hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 99\n"
     ]
    }
   ],
   "source": [
    "device = \"cpu\" #[\"cpu\", \"mps\", \"cuda\", \"tpu\", \"hpu\"]\n",
    "pl.seed_everything(seed)\n",
    "\n",
    "hidden_size = 64\n",
    "lr = 3e-2\n",
    "rnn_layers = 1\n",
    "max_epochs = 5\n",
    "\n",
    "weight_decay = 1e-2\n",
    "cell_type = 'GRU' # ['LSTM', 'GRU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(accelerator=device, gradient_clip_val=1e-1)\n",
    "net = GRU.from_dataset(\n",
    "    training,\n",
    "    learning_rate=lr,\n",
    "    hidden_size=hidden_size,\n",
    "    rnn_layers=rnn_layers,\n",
    "    loss=NormalDistributionLoss(),\n",
    "    optimizer=\"Adam\",\n",
    "    input_size=1, \n",
    "    sequence_length=width,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding best initial lr:  85%|████████▌ | 85/100 [00:01<00:00, 83.46it/s]\n",
      "LR finder stopped early after 85 steps due to diverging loss.\n",
      "Learning rate set to 4.57088189614875e-06\n",
      "Restoring states from the checkpoint path at /Users/hchen/gp-mjo/SINDy_RealData/experiments/.lr_find_a11ef8d0-5583-4b58-919d-2cda88c826c3.ckpt\n",
      "Restored all states from the checkpoint at /Users/hchen/gp-mjo/SINDy_RealData/experiments/.lr_find_a11ef8d0-5583-4b58-919d-2cda88c826c3.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suggested learning rate: 4.57088189614875e-06\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# find optimal learning rate\n",
    "res = Tuner(trainer).lr_find(\n",
    "    net,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    "    min_lr=1e-6,\n",
    "    max_lr=1e0,\n",
    "    early_stop_threshold=100,\n",
    ")\n",
    "print(f\"suggested learning rate: {res.suggestion()}\")\n",
    "fig = res.plot(show=True, suggest=True)\n",
    "fig.show()\n",
    "net.hparams.learning_rate = res.suggestion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type                   | Params | Mode \n",
      "-------------------------------------------------------------------\n",
      "0 | loss            | NormalDistributionLoss | 0      | train\n",
      "1 | logging_metrics | ModuleList             | 0      | train\n",
      "2 | network         | GRUModule              | 473 K  | train\n",
      "-------------------------------------------------------------------\n",
      "473 K     Trainable params\n",
      "0         Non-trainable params\n",
      "473 K     Total params\n",
      "1.895     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 50/50 [06:57<00:00,  0.12it/s, v_num=120, train_loss_step=1.810, val_loss=1.590, train_loss_epoch=1.570]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 50/50 [06:57<00:00,  0.12it/s, v_num=120, train_loss_step=1.810, val_loss=1.590, train_loss_epoch=1.570]\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 3\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=10, verbose=False, mode=\"min\")\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=max_epochs,\n",
    "    accelerator=device,\n",
    "    enable_model_summary=True,\n",
    "    gradient_clip_val=0.1,\n",
    "    callbacks=[early_stop_callback],\n",
    "    limit_train_batches=50,\n",
    "    enable_checkpointing=True,\n",
    ")\n",
    "\n",
    "\n",
    "net = GRU.from_dataset(\n",
    "    training,\n",
    "    learning_rate=res.suggestion(),\n",
    "    log_interval=10,\n",
    "    log_val_interval=1,\n",
    "    hidden_size=hidden_size,\n",
    "    rnn_layers=rnn_layers,\n",
    "    optimizer=\"Adam\",\n",
    "    loss=NormalDistributionLoss(),\n",
    "    input_size=1, \n",
    "    sequence_length=width,\n",
    ")\n",
    "\n",
    "trainer.fit(\n",
    "    net,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "best_model = GRU.load_from_checkpoint(best_model_path)\n",
    "\n",
    "# best_model = net\n",
    "predictions = best_model.predict(test_dataloader, mode=\"prediction\", \n",
    "                                trainer_kwargs=dict(accelerator=device), \n",
    "                                return_index=True, return_x=True, return_y=True)\n",
    "\n",
    "raw_predictions = net.predict(\n",
    "    test_dataloader, mode=\"raw\", \n",
    "    return_index=True, return_x=True, return_y=True, \n",
    "    n_samples=100, \n",
    "    trainer_kwargs=dict(accelerator=device)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.4858876   1.4127605   0.87013769  0.36032364 -0.2242689  -0.52937448\n",
      " -0.56909633 -0.33208254]\n",
      "[2.1454837 2.9190524 3.2660966 3.2806582 3.2044053 3.2006223 2.7466192\n",
      " 2.1816049]\n",
      "tensor([[ 1.4859,  1.4128,  0.8701,  0.3603, -0.2243, -0.5294, -0.5691, -0.3321],\n",
      "        [ 2.1455,  2.9191,  3.2661,  3.2807,  3.2044,  3.2006,  2.7466,  2.1816],\n",
      "        [ 1.4128,  0.8701,  0.3603, -0.2243, -0.5294, -0.5691, -0.3321, -0.0778],\n",
      "        [ 2.9191,  3.2661,  3.2807,  3.2044,  3.2006,  2.7466,  2.1816,  1.7408]])\n",
      "tensor([[-0.0667, -0.0295,  0.0065, -0.0817, -0.1059,  0.0724,  0.0290,  0.0653],\n",
      "        [ 0.0550, -0.0689,  0.0287,  0.0032,  0.1169,  0.0156,  0.0694, -0.1889],\n",
      "        [-0.1571,  0.0519,  0.1923, -0.1118, -0.0701,  0.0830, -0.0470, -0.0582],\n",
      "        [ 0.1582,  0.0454, -0.0776,  0.0162, -0.0015,  0.0091, -0.0500, -0.1015]])\n"
     ]
    }
   ],
   "source": [
    "print( entire_npzfile['RMM1'][start_forecast_test:start_forecast_test+8] )\n",
    "print( entire_npzfile['RMM2'][start_forecast_test:start_forecast_test+8] )\n",
    "print(raw_predictions.x['decoder_target'][:4, :8])\n",
    "print(raw_predictions.output[0].mean(dim=-1)[:4, :8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9263)\n",
      "tensor(0.9290)\n"
     ]
    }
   ],
   "source": [
    "lead_time_id = 0\n",
    "print( \n",
    "    RMSE()(raw_predictions.x['decoder_target'].squeeze()[:,lead_time_id][None,:], \n",
    "        raw_predictions.output[0].mean(dim=-1)[:,lead_time_id][None,:])\n",
    ")\n",
    "\n",
    "print(\n",
    "    RMSE()(predictions.x['decoder_target'][:,lead_time_id][:,None], \n",
    "       predictions.output[:,lead_time_id][:,None])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModule(nn.Module):\n",
    "    def __init__(self, input_size: int, output_size: int, hidden_size: int, \n",
    "                rnn_layers: int, sequence_length: int, n_outputs: int):\n",
    "        super(LSTMModule, self).__init__()\n",
    "        \n",
    "        self.hidden_size  = hidden_size\n",
    "        self.rnn_layers = rnn_layers\n",
    "        self.sequence_length = sequence_length\n",
    "        self.n_outputs = n_outputs\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, rnn_layers, \n",
    "                        batch_first=True, bidirectional=False)\n",
    "        self.fc1 = nn.Linear(hidden_size * sequence_length, output_size)\n",
    "\n",
    "        module_list = []\n",
    "        module_list.append(nn.Linear(hidden_size * sequence_length, output_size * n_outputs))\n",
    "        self.fc = nn.Sequential(*module_list)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x is of size [batch_size, sequence_length, input_size]\n",
    "        h0 = torch.zeros(self.rnn_layers, x.size(0), self.hidden_size, device=x.device)\n",
    "        c0 = torch.zeros(self.rnn_layers, x.size(0), self.hidden_size, device=x.device)\n",
    "        \n",
    "        out, _ = self.lstm(x,(h0, c0)) # [batch_size, sequence_length, hidden_size]\n",
    "        # Reshaping the outputs in the shape of (batch_size, seq_length, hidden_size)\n",
    "        # so that it can fit into the fully connected layer\n",
    "        # out = out[:, -1, :]\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "\n",
    "        out = out.reshape(out.shape[0], -1, self.n_outputs)\n",
    "        return out\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"hidden_size\":                 10\n",
       "\"input_size\":                  1\n",
       "\"learning_rate\":               0.001\n",
       "\"log_gradient_flow\":           False\n",
       "\"log_interval\":                -1\n",
       "\"log_val_interval\":            -1\n",
       "\"logging_metrics\":             ModuleList()\n",
       "\"monotone_constaints\":         {}\n",
       "\"optimizer\":                   Ranger\n",
       "\"optimizer_params\":            None\n",
       "\"output_size\":                 60\n",
       "\"output_transformer\":          TorchNormalizer(method='identity', center=True, transformation=None, method_kwargs={})\n",
       "\"reduce_on_plateau_min_lr\":    1e-05\n",
       "\"reduce_on_plateau_patience\":  1000\n",
       "\"reduce_on_plateau_reduction\": 2.0\n",
       "\"rnn_layers\":                  1\n",
       "\"sequence_length\":             40\n",
       "\"weight_decay\":                0.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LSTM(BaseModel):  # we inherit the `from_dataset` method\n",
    "    def __init__(self, input_size: int, output_size: int, hidden_size: int, \n",
    "                rnn_layers: int, sequence_length: int, **kwargs):\n",
    "        # saves arguments in signature to `.hparams` attribute, mandatory call - do not skip this\n",
    "        self.save_hyperparameters()\n",
    "        # pass additional arguments to BaseModel.__init__, mandatory call - do not skip this\n",
    "        super().__init__(**kwargs)\n",
    "        self.network = LSTMModule(\n",
    "            input_size=self.hparams.input_size,\n",
    "            output_size=self.hparams.output_size,\n",
    "            hidden_size=self.hparams.hidden_size,\n",
    "            rnn_layers=self.hparams.rnn_layers,\n",
    "            sequence_length=self.hparams.sequence_length,\n",
    "            n_outputs=2,  # <<<<<<<< we predict two outputs for mean and scale of the normal distribution\n",
    "        )\n",
    "        self.loss = NormalDistributionLoss()\n",
    "\n",
    "    @classmethod\n",
    "    def from_dataset(cls, dataset: TimeSeriesDataSet, **kwargs):\n",
    "        new_kwargs = {\n",
    "            \"output_size\": dataset.max_prediction_length,\n",
    "            \"input_size\": 1,#dataset.max_encoder_length,\n",
    "            \"sequence_length\": dataset.max_encoder_length,\n",
    "        }\n",
    "        new_kwargs.update(kwargs)  # use to pass real hyperparameters and override defaults set by dataset\n",
    "        # example for dataset validation\n",
    "        assert dataset.max_prediction_length == dataset.min_prediction_length, \"Decoder only supports a fixed length\"\n",
    "        assert dataset.min_encoder_length == dataset.max_encoder_length, \"Encoder only supports a fixed length\"\n",
    "        assert (\n",
    "            len(dataset.time_varying_known_categoricals) == 0\n",
    "            and len(dataset.time_varying_known_reals) == 0\n",
    "            and len(dataset.time_varying_unknown_categoricals) == 0\n",
    "            and len(dataset.static_categoricals) == 0\n",
    "            and len(dataset.static_reals) == 0\n",
    "            and len(dataset.time_varying_unknown_reals) == 1\n",
    "            and dataset.time_varying_unknown_reals[0] == dataset.target\n",
    "        ), \"Only covariate should be the target in 'time_varying_unknown_reals'\"\n",
    "\n",
    "        return super().from_dataset(dataset, **new_kwargs)\n",
    "\n",
    "    def forward(self, x: Dict[str, torch.Tensor], n_samples: int = None) -> Dict[str, torch.Tensor]:\n",
    "        # x is a batch generated based on the TimeSeriesDataset\n",
    "        network_input = x[\"encoder_cont\"]\n",
    "        prediction = self.network(network_input)  # shape batch_size x n_decoder_steps x 2\n",
    "        # we need to scale the parameters to real space\n",
    "        prediction = self.transform_output(\n",
    "            prediction=prediction,\n",
    "            target_scale=x[\"target_scale\"],\n",
    "        )\n",
    "        if n_samples is not None:\n",
    "            # sample from distribution\n",
    "            prediction = self.loss.sample(prediction, n_samples)\n",
    "        # The conversion to a named tuple can be directly achieved with the `to_network_output` function.\n",
    "        return self.to_network_output(prediction=prediction)\n",
    "\n",
    "\n",
    "model = LSTM.from_dataset(training, hidden_size=10, rnn_layers=1, \n",
    "                        input_size=1, sequence_length=width)\n",
    "model.hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 99\n"
     ]
    }
   ],
   "source": [
    "device = \"cpu\" #[\"cpu\", \"mps\", \"cuda\", \"tpu\", \"hpu\"]\n",
    "pl.seed_everything(seed)\n",
    "\n",
    "hidden_size = 64\n",
    "lr = 3e-2\n",
    "rnn_layers = 1\n",
    "max_epochs = 5\n",
    "\n",
    "weight_decay = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(accelerator=device, gradient_clip_val=1e-1)\n",
    "net = LSTM.from_dataset(\n",
    "    training,\n",
    "    learning_rate=lr,\n",
    "    hidden_size=hidden_size,\n",
    "    rnn_layers=rnn_layers,\n",
    "    loss=NormalDistributionLoss(),\n",
    "    optimizer=\"Adam\",\n",
    "    # input_size=1, \n",
    "    # sequence_length=width,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding best initial lr:  98%|█████████▊| 98/100 [00:01<00:00, 85.40it/s]`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Finding best initial lr: 100%|██████████| 100/100 [00:01<00:00, 81.81it/s]\n",
      "Learning rate set to 4.57088189614875e-06\n",
      "Restoring states from the checkpoint path at /Users/hchen/gp-mjo/SINDy_RealData/experiments/.lr_find_efdc8142-b8cb-446b-b968-24d41ef91b9b.ckpt\n",
      "Restored all states from the checkpoint at /Users/hchen/gp-mjo/SINDy_RealData/experiments/.lr_find_efdc8142-b8cb-446b-b968-24d41ef91b9b.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suggested learning rate: 4.57088189614875e-06\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# find optimal learning rate\n",
    "res = Tuner(trainer).lr_find(\n",
    "    net,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    "    min_lr=1e-6,\n",
    "    max_lr=1e0,\n",
    "    early_stop_threshold=100,\n",
    ")\n",
    "print(f\"suggested learning rate: {res.suggestion()}\")\n",
    "fig = res.plot(show=True, suggest=True)\n",
    "fig.show()\n",
    "net.hparams.learning_rate = res.suggestion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type                   | Params | Mode \n",
      "-------------------------------------------------------------------\n",
      "0 | loss            | NormalDistributionLoss | 0      | train\n",
      "1 | logging_metrics | ModuleList             | 0      | train\n",
      "2 | network         | LSTMModule             | 478 K  | train\n",
      "-------------------------------------------------------------------\n",
      "478 K     Trainable params\n",
      "0         Non-trainable params\n",
      "478 K     Total params\n",
      "1.913     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 50/50 [06:35<00:00,  0.13it/s, v_num=125, train_loss_step=1.760, val_loss=1.590, train_loss_epoch=1.570]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 50/50 [06:35<00:00,  0.13it/s, v_num=125, train_loss_step=1.760, val_loss=1.590, train_loss_epoch=1.570]\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 3\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=10, verbose=False, mode=\"min\")\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=max_epochs,\n",
    "    accelerator=device,\n",
    "    enable_model_summary=True,\n",
    "    gradient_clip_val=0.1,\n",
    "    callbacks=[early_stop_callback],\n",
    "    limit_train_batches=50,\n",
    "    enable_checkpointing=True,\n",
    ")\n",
    "\n",
    "\n",
    "net = LSTM.from_dataset(\n",
    "    training,\n",
    "    learning_rate=res.suggestion(),\n",
    "    log_interval=10,\n",
    "    log_val_interval=1,\n",
    "    hidden_size=hidden_size,\n",
    "    rnn_layers=rnn_layers,\n",
    "    optimizer=\"Adam\",\n",
    "    loss=NormalDistributionLoss(),\n",
    "    # input_size=1, \n",
    "    # sequence_length=width,\n",
    ")\n",
    "\n",
    "trainer.fit(\n",
    "    net,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "best_model = GRU.load_from_checkpoint(best_model_path)\n",
    "\n",
    "# best_model = net\n",
    "predictions = best_model.predict(test_dataloader, mode=\"prediction\", \n",
    "                                trainer_kwargs=dict(accelerator=device), \n",
    "                                return_index=True, return_x=True, return_y=True)\n",
    "\n",
    "raw_predictions = net.predict(\n",
    "    test_dataloader, mode=\"raw\", \n",
    "    return_index=True, return_x=True, return_y=True, \n",
    "    n_samples=100, \n",
    "    trainer_kwargs=dict(accelerator=device)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( entire_npzfile['RMM1'][start_forecast_test:start_forecast_test+8] )\n",
    "print( entire_npzfile['RMM2'][start_forecast_test:start_forecast_test+8] )\n",
    "print(raw_predictions.x['decoder_target'][:4, :8])\n",
    "print(raw_predictions.output[0].mean(dim=-1)[:4, :8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_time_id = 0\n",
    "print( \n",
    "    RMSE()(raw_predictions.x['decoder_target'].squeeze()[:,lead_time_id][None,:], \n",
    "        raw_predictions.output[0].mean(dim=-1)[:,lead_time_id][None,:])\n",
    ")\n",
    "\n",
    "print(\n",
    "    RMSE()(predictions.x['decoder_target'][:,lead_time_id][:,None], \n",
    "       predictions.output[:,lead_time_id][:,None])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCNModule(nn.Module):\n",
    "    def __init__(self, input_size: int, output_size: int, hidden_size: int, n_hidden_layers: int, n_outputs: int):\n",
    "        super().__init__()\n",
    "\n",
    "        # input layer\n",
    "        module_list = [nn.Linear(input_size, hidden_size), nn.ReLU()]\n",
    "        # hidden layers\n",
    "        for _ in range(n_hidden_layers):\n",
    "            module_list.extend([nn.Linear(hidden_size, hidden_size), nn.ReLU()])\n",
    "        # output layer\n",
    "        self.n_outputs = n_outputs\n",
    "        module_list.append(\n",
    "            nn.Linear(hidden_size, output_size * n_outputs)\n",
    "        )  # <<<<<<<< modified: replaced output_size with output_size * n_outputs\n",
    "\n",
    "        self.sequential = nn.Sequential(*module_list)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x of shape: batch_size x n_timesteps_in\n",
    "        # output of shape batch_size x n_timesteps_out\n",
    "        return self.sequential(x).reshape(x.size(0), -1, self.n_outputs)  # <<<<<<<< modified: added reshape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"hidden_size\":                 10\n",
       "\"input_size\":                  40\n",
       "\"learning_rate\":               0.001\n",
       "\"log_gradient_flow\":           False\n",
       "\"log_interval\":                -1\n",
       "\"log_val_interval\":            -1\n",
       "\"logging_metrics\":             ModuleList()\n",
       "\"monotone_constaints\":         {}\n",
       "\"n_hidden_layers\":             2\n",
       "\"optimizer\":                   Ranger\n",
       "\"optimizer_params\":            None\n",
       "\"output_size\":                 60\n",
       "\"output_transformer\":          TorchNormalizer(method='identity', center=True, transformation=None, method_kwargs={})\n",
       "\"reduce_on_plateau_min_lr\":    1e-05\n",
       "\"reduce_on_plateau_patience\":  1000\n",
       "\"reduce_on_plateau_reduction\": 2.0\n",
       "\"weight_decay\":                0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FCN(BaseModel):  # we inherit the `from_dataset` method\n",
    "    def __init__(self, input_size: int, output_size: int, hidden_size: int, n_hidden_layers: int, **kwargs):\n",
    "        # saves arguments in signature to `.hparams` attribute, mandatory call - do not skip this\n",
    "        self.save_hyperparameters()\n",
    "        # pass additional arguments to BaseModel.__init__, mandatory call - do not skip this\n",
    "        super().__init__(**kwargs)\n",
    "        self.network = FCNModule(\n",
    "            input_size=self.hparams.input_size,\n",
    "            output_size=self.hparams.output_size,\n",
    "            hidden_size=self.hparams.hidden_size,\n",
    "            n_hidden_layers=self.hparams.n_hidden_layers,\n",
    "            n_outputs=2,  # <<<<<<<< we predict two outputs for mean and scale of the normal distribution\n",
    "        )\n",
    "        self.loss = NormalDistributionLoss()\n",
    "\n",
    "    @classmethod\n",
    "    def from_dataset(cls, dataset: TimeSeriesDataSet, **kwargs):\n",
    "        new_kwargs = {\n",
    "            \"output_size\": dataset.max_prediction_length,\n",
    "            \"input_size\": dataset.max_encoder_length,\n",
    "        }\n",
    "        new_kwargs.update(kwargs)  # use to pass real hyperparameters and override defaults set by dataset\n",
    "        # example for dataset validation\n",
    "        assert dataset.max_prediction_length == dataset.min_prediction_length, \"Decoder only supports a fixed length\"\n",
    "        assert dataset.min_encoder_length == dataset.max_encoder_length, \"Encoder only supports a fixed length\"\n",
    "        assert (\n",
    "            len(dataset.time_varying_known_categoricals) == 0\n",
    "            and len(dataset.time_varying_known_reals) == 0\n",
    "            and len(dataset.time_varying_unknown_categoricals) == 0\n",
    "            and len(dataset.static_categoricals) == 0\n",
    "            and len(dataset.static_reals) == 0\n",
    "            and len(dataset.time_varying_unknown_reals) == 1\n",
    "            and dataset.time_varying_unknown_reals[0] == dataset.target\n",
    "        ), \"Only covariate should be the target in 'time_varying_unknown_reals'\"\n",
    "\n",
    "        return super().from_dataset(dataset, **new_kwargs)\n",
    "\n",
    "    def forward(self, x: Dict[str, torch.Tensor], n_samples: int = None) -> Dict[str, torch.Tensor]:\n",
    "        # x is a batch generated based on the TimeSeriesDataset\n",
    "        network_input = x[\"encoder_cont\"].squeeze(-1)\n",
    "        prediction = self.network(network_input)  # shape batch_size x n_decoder_steps x 2\n",
    "        # we need to scale the parameters to real space\n",
    "        prediction = self.transform_output(\n",
    "            prediction=prediction,\n",
    "            target_scale=x[\"target_scale\"],\n",
    "        )\n",
    "        if n_samples is not None:\n",
    "            # sample from distribution\n",
    "            prediction = self.loss.sample(prediction, n_samples)\n",
    "        # The conversion to a named tuple can be directly achieved with the `to_network_output` function.\n",
    "        return self.to_network_output(prediction=prediction)\n",
    "\n",
    "\n",
    "model = FCN.from_dataset(training, hidden_size=10, n_hidden_layers=2)\n",
    "model.hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 99\n"
     ]
    }
   ],
   "source": [
    "device = \"cpu\" #[\"cpu\", \"mps\", \"cuda\", \"tpu\", \"hpu\"]\n",
    "pl.seed_everything(seed)\n",
    "\n",
    "hidden_size = 64\n",
    "lr = 3e-2\n",
    "rnn_layers = 1\n",
    "max_epochs = 3\n",
    "n_hidden_layers=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(accelerator=device, gradient_clip_val=1e-1)\n",
    "net = FCN.from_dataset(\n",
    "    training,\n",
    "    learning_rate=lr,\n",
    "    hidden_size=hidden_size,\n",
    "    n_hidden_layers=n_hidden_layers,\n",
    "    loss=NormalDistributionLoss(),\n",
    "    optimizer=\"Adam\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding best initial lr:  92%|█████████▏| 92/100 [00:00<00:00, 443.53it/s]\n",
      "LR finder stopped early after 92 steps due to diverging loss.\n",
      "Learning rate set to 0.1445439770745927\n",
      "Restoring states from the checkpoint path at /Users/hchen/gp-mjo/SINDy_RealData/experiments/.lr_find_9f99eb30-b2a2-4065-93d8-2b15e91ad322.ckpt\n",
      "Restored all states from the checkpoint at /Users/hchen/gp-mjo/SINDy_RealData/experiments/.lr_find_9f99eb30-b2a2-4065-93d8-2b15e91ad322.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suggested learning rate: 0.1445439770745927\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# find optimal learning rate\n",
    "res = Tuner(trainer).lr_find(\n",
    "    net,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    "    min_lr=1e-6,\n",
    "    max_lr=1e0,\n",
    "    early_stop_threshold=100,\n",
    ")\n",
    "print(f\"suggested learning rate: {res.suggestion()}\")\n",
    "fig = res.plot(show=True, suggest=True)\n",
    "fig.show()\n",
    "net.hparams.learning_rate = res.suggestion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type                   | Params | Mode \n",
      "-------------------------------------------------------------------\n",
      "0 | loss            | NormalDistributionLoss | 0      | train\n",
      "1 | logging_metrics | ModuleList             | 0      | train\n",
      "2 | network         | FCNModule              | 14.6 K | train\n",
      "-------------------------------------------------------------------\n",
      "14.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "14.6 K    Total params\n",
      "0.058     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   4%|▍         | 2/50 [02:22<57:04,  0.01it/s, v_num=96, train_loss_step=7.27e+14]\n",
      "Epoch 2: 100%|██████████| 50/50 [03:21<00:00,  0.25it/s, v_num=98, train_loss_step=1.770, val_loss=1.430, train_loss_epoch=1.460]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 50/50 [03:21<00:00,  0.25it/s, v_num=98, train_loss_step=1.770, val_loss=1.430, train_loss_epoch=1.460]\n"
     ]
    }
   ],
   "source": [
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=10, verbose=False, mode=\"min\")\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=max_epochs,\n",
    "    accelerator=device,\n",
    "    enable_model_summary=True,\n",
    "    gradient_clip_val=0.1,\n",
    "    callbacks=[early_stop_callback],\n",
    "    limit_train_batches=50,\n",
    "    enable_checkpointing=True,\n",
    ")\n",
    "\n",
    "\n",
    "net = FCN.from_dataset(\n",
    "    training,\n",
    "    # learning_rate=res.suggestion(),\n",
    "    log_interval=10,\n",
    "    log_val_interval=1,\n",
    "    hidden_size=hidden_size,\n",
    "    n_hidden_layers=n_hidden_layers,\n",
    "    optimizer=\"Adam\",\n",
    "    loss=NormalDistributionLoss(),\n",
    ")\n",
    "\n",
    "trainer.fit(\n",
    "    net,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "best_model = FCN.load_from_checkpoint(best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# best_model = net\n",
    "predictions = best_model.predict(test_dataloader, mode=\"prediction\", \n",
    "                                trainer_kwargs=dict(accelerator=device), \n",
    "                                return_index=True, return_x=True, return_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "raw_predictions = net.predict(\n",
    "    test_dataloader, mode=\"raw\", \n",
    "    return_index=True, return_x=True, return_y=True, \n",
    "    n_samples=100, \n",
    "    trainer_kwargs=dict(accelerator=device)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1056, 60, 100])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_predictions.output[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.4858876   1.4127605   0.87013769  0.36032364 -0.2242689  -0.52937448\n",
      " -0.56909633 -0.33208254]\n",
      "[2.1454837 2.9190524 3.2660966 3.2806582 3.2044053 3.2006223 2.7466192\n",
      " 2.1816049]\n",
      "tensor([[ 1.4859,  1.4128,  0.8701,  0.3603, -0.2243, -0.5294, -0.5691, -0.3321],\n",
      "        [ 2.1455,  2.9191,  3.2661,  3.2807,  3.2044,  3.2006,  2.7466,  2.1816],\n",
      "        [ 1.4128,  0.8701,  0.3603, -0.2243, -0.5294, -0.5691, -0.3321, -0.0778],\n",
      "        [ 2.9191,  3.2661,  3.2807,  3.2044,  3.2006,  2.7466,  2.1816,  1.7408]])\n",
      "tensor([[ 0.6157,  0.5562,  0.2558,  0.6585,  0.5660,  0.0780,  0.3375,  0.0535],\n",
      "        [ 0.6736,  0.6732,  0.5957,  1.0690,  0.6387,  0.4163,  0.6208,  0.4220],\n",
      "        [ 0.5565,  0.5274,  0.2114,  0.4212,  0.4629, -0.0373,  0.1066, -0.1597],\n",
      "        [ 0.5997,  0.6609,  0.6632,  1.1282,  0.7291,  0.3404,  0.4386,  0.2999]])\n"
     ]
    }
   ],
   "source": [
    "id = 0\n",
    "print( entire_npzfile['RMM1'][start_forecast_test:start_forecast_test+8] )\n",
    "print( entire_npzfile['RMM2'][start_forecast_test:start_forecast_test+8] )\n",
    "print(raw_predictions.x['decoder_target'][:4, :8])\n",
    "print(raw_predictions.output[0].mean(dim=-1)[:4, :8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6956)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lead_time_id = 0\n",
    "RMSE()(raw_predictions.x['decoder_target'].squeeze()[:,lead_time_id][None,:], \n",
    "       raw_predictions.output[0].mean(dim=-1)[:,lead_time_id][None,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6963)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lead_time_id = 0\n",
    "RMSE()(predictions.x['decoder_target'][:,lead_time_id][:,None], \n",
    "       predictions.output[:,lead_time_id][:,None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "pl.seed_everything(42)\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=\"cpu\",\n",
    "    # clipping gradients is a hyperparameter and important to prevent divergance\n",
    "    # of the gradient for recurrent neural networks\n",
    "    gradient_clip_val=0.1,\n",
    ")\n",
    "\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    # not meaningful for finding the learning rate but otherwise very important\n",
    "    learning_rate=0.03,\n",
    "    hidden_size=8,  # most important hyperparameter apart from learning rate\n",
    "    # number of attention heads. Set to up to 4 for large datasets\n",
    "    attention_head_size=1,\n",
    "    dropout=0.1,  # between 0.1 and 0.3 are good values\n",
    "    hidden_continuous_size=8,  # set to <= hidden_size\n",
    "    loss=QuantileLoss(),\n",
    "    optimizer=\"Ranger\"\n",
    "    # reduce learning rate if no improvement in validation loss after x epochs\n",
    "    # reduce_on_plateau_patience=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = Tuner(trainer).lr_find(\n",
    "#     tft,\n",
    "#     train_dataloaders=train_dataloader,\n",
    "#     val_dataloaders=val_dataloader,\n",
    "#     max_lr=10.0,\n",
    "#     min_lr=1e-6,\n",
    "# )\n",
    "\n",
    "# print(f\"suggested learning rate: {res.suggestion()}\")\n",
    "# fig = res.plot(show=True, suggest=True)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n",
      "\n",
      "   | Name                               | Type                            | Params | Mode \n",
      "------------------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0      | train\n",
      "1  | logging_metrics                    | ModuleList                      | 0      | train\n",
      "2  | input_embeddings                   | MultiEmbedding                  | 2      | train\n",
      "3  | prescalers                         | ModuleDict                      | 16     | train\n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 48     | train\n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 528    | train\n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 0      | train\n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 1.1 K  | train\n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 1.1 K  | train\n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 1.1 K  | train\n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 1.1 K  | train\n",
      "11 | lstm_encoder                       | LSTM                            | 2.2 K  | train\n",
      "12 | lstm_decoder                       | LSTM                            | 2.2 K  | train\n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 544    | train\n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 32     | train\n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 1.4 K  | train\n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 808    | train\n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 576    | train\n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 1.1 K  | train\n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 576    | train\n",
      "20 | output_layer                       | Linear                          | 119    | train\n",
      "------------------------------------------------------------------------------------------------\n",
      "14.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "14.6 K    Total params\n",
      "0.058     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# configure network and trainer\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=10, verbose=False, mode=\"min\")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=50,\n",
    "    accelerator=\"cpu\",\n",
    "    enable_model_summary=True,\n",
    "    gradient_clip_val=0.1,\n",
    "    limit_train_batches=50,  # coment in for training, running valiation every 30 batches\n",
    "    fast_dev_run=True,  # comment in to check that networkor dataset has no serious bugs\n",
    "    callbacks=[early_stop_callback],\n",
    ")\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    learning_rate=0.03,\n",
    "    hidden_size=16,\n",
    "    attention_head_size=2,\n",
    "    dropout=0.1,\n",
    "    hidden_continuous_size=8,\n",
    "    loss=QuantileLoss(),\n",
    "    log_interval=10,  # uncomment for learning rate finder and otherwise, e.g. to 10 for logging every 10 batches\n",
    "    optimizer=\"Ranger\",\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "\n",
    "# fit network\n",
    "trainer.fit(\n",
    "    tft,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_gp_mjo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
